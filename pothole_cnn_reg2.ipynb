{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(3840, 2160)):\n",
    "    # Load the original image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Resize the image to the target dimensions (3840x2160)\n",
    "    image = image.resize(target_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Convert the image to a numpy array and normalize\n",
    "    image_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_heatmap(heatmap_path):\n",
    "    # Assuming grayscale heatmap\n",
    "    heatmap = cv2.imread(heatmap_path, cv2.IMREAD_GRAYSCALE)\n",
    "    heatmap = heatmap / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Convert grayscale heatmap to 3D by adding a channel dimension\n",
    "    heatmap = np.expand_dims(heatmap, axis=-1)\n",
    "\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_input(image_array, heatmap_array):\n",
    "    # Ensure image_array and heatmap_array have the same dimensions\n",
    "    if image_array.shape[:2] != heatmap_array.shape[:2]:\n",
    "        raise ValueError(\n",
    "            \"Image and heatmap must have the same spatial dimensions\")\n",
    "\n",
    "    # Stack the image (3 channels) and heatmap (1 channel) into a 4-channel input\n",
    "    combined_input = np.concatenate([image_array, heatmap_array], axis=-1)\n",
    "\n",
    "    return combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training labels from csv as dict\n",
    "def load_labels_from_csv(csv_path):\n",
    "    labels = {}\n",
    "    with open(csv_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            labels[row[0]] = row[1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = load_labels_from_csv('./data_full/filtered_train_labels_reduced.csv')\n",
    "# val_labels = load_labels_from_csv('./data_full/validation_labels.csv')\n",
    "combined_labels = load_labels_from_csv('./data_full/filtered_train_labels.csv')\n",
    "test_labels = load_labels_from_csv('./data_full/test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is to fix the DataFrames from csv to measurement feature format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./good_data/data/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pothole number</th>\n",
       "      <th>width_mm</th>\n",
       "      <th>height_mm</th>\n",
       "      <th>area_mm2</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>depth_mm</th>\n",
       "      <th>avg_intensity</th>\n",
       "      <th>intensity_range</th>\n",
       "      <th>intensity_std</th>\n",
       "      <th>severity_index</th>\n",
       "      <th>depth_area_interaction</th>\n",
       "      <th>depth_width_interaction</th>\n",
       "      <th>depth_height_interaction</th>\n",
       "      <th>Bags used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>0.562042</td>\n",
       "      <td>0.397217</td>\n",
       "      <td>0.298381</td>\n",
       "      <td>0.267583</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>0.459542</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>0.494798</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.215819</td>\n",
       "      <td>0.437546</td>\n",
       "      <td>0.331561</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>0.572546</td>\n",
       "      <td>0.173004</td>\n",
       "      <td>0.174225</td>\n",
       "      <td>0.593524</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.742875</td>\n",
       "      <td>0.164402</td>\n",
       "      <td>0.181747</td>\n",
       "      <td>0.596370</td>\n",
       "      <td>0.275671</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0.489001</td>\n",
       "      <td>0.458246</td>\n",
       "      <td>0.300131</td>\n",
       "      <td>0.178247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951759</td>\n",
       "      <td>0.330843</td>\n",
       "      <td>0.326775</td>\n",
       "      <td>0.600077</td>\n",
       "      <td>0.551334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>0.270496</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>0.067384</td>\n",
       "      <td>0.451608</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.614842</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.021065</td>\n",
       "      <td>0.045327</td>\n",
       "      <td>0.194506</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>0.381871</td>\n",
       "      <td>0.256768</td>\n",
       "      <td>0.163278</td>\n",
       "      <td>0.280154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pothole number  width_mm  height_mm  area_mm2  aspect_ratio  depth_mm  \\\n",
       "0             103  0.562042   0.397217  0.298381      0.267583  0.663934   \n",
       "1             104  0.572546   0.173004  0.174225      0.593524  0.893443   \n",
       "2             105  0.489001   0.458246  0.300131      0.178247  1.000000   \n",
       "3             108  0.270496   0.087696  0.067384      0.451608  0.459016   \n",
       "4             114  0.381871   0.256768  0.163278      0.280154  0.000000   \n",
       "\n",
       "   avg_intensity  intensity_range  intensity_std  severity_index  \\\n",
       "0       0.459542         0.663934       0.494798        0.145074   \n",
       "1       0.702520         0.893443       0.742875        0.164402   \n",
       "2       0.444247         1.000000       0.951759        0.330843   \n",
       "3       0.614842         0.459016       0.302400        0.021065   \n",
       "4       0.000000         0.000000       0.000000        0.000000   \n",
       "\n",
       "   depth_area_interaction  depth_width_interaction  depth_height_interaction  \\\n",
       "0                0.215819                 0.437546                  0.331561   \n",
       "1                0.181747                 0.596370                  0.275671   \n",
       "2                0.326775                 0.600077                  0.551334   \n",
       "3                0.045327                 0.194506                  0.108300   \n",
       "4                0.000000                 0.000000                  0.000000   \n",
       "\n",
       "   Bags used   \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pothole number from int to string and add p in front and .jpg at the end\n",
    "# df['Pothole number'] = df['Pothole number'].apply(lambda x: 'p' + str(x) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = df['Pothole number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['Pothole number'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_json('./good_data/data/test_processed.json', orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotholeDataset(Dataset):\n",
    "    def __init__(self, image_dir, heatmap_dir, measurement_features_file, labels, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.heatmap_dir = heatmap_dir\n",
    "        self.transform = transform\n",
    "        self.labels = labels\n",
    "\n",
    "        # Load measurement features from JSON\n",
    "        with open(measurement_features_file, 'r') as f:\n",
    "            self.measurement_features = json.load(f)\n",
    "\n",
    "        # List all image filenames\n",
    "        self.image_filenames = list(self.measurement_features.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_filenames[idx]\n",
    "\n",
    "        # Load the raw image\n",
    "        image_path = os.path.join(self.image_dir, image_filename)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Load the heatmap\n",
    "        heatmap_path = os.path.join(self.heatmap_dir, image_filename.replace('.jpg', '.png'))\n",
    "        heatmap = Image.open(heatmap_path).convert('L')  # Load as grayscale\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            heatmap = self.transform(heatmap)\n",
    "\n",
    "        # Load the measurement features\n",
    "        measurement_features = torch.tensor(\n",
    "            list(self.measurement_features[image_filename].values())[:-1], dtype=torch.float32)\n",
    "        \n",
    "        # all_features = torch.tensor(np.array([torch.tensor(list(\n",
    "        #     self.measurement_features[i].values()), dtype=torch.float32) for i in self.measurement_features.keys()]))\n",
    "\n",
    "        # means = torch.mean(all_features, axis=0)\n",
    "        # stds = torch.std(all_features, axis=0)\n",
    "        \n",
    "        # Normalize the measurement features (if needed)\n",
    "        # if sum(measurement_features) != 0:\n",
    "        #     measurement_features = (measurement_features - means) / stds\n",
    "\n",
    "        # Combine image and heatmap into a 4-channel tensor\n",
    "        combined_input = torch.cat((image, heatmap), dim=0)\n",
    "\n",
    "        if self.labels==test_labels:\n",
    "            target = torch.nan\n",
    "        else:\n",
    "            target = torch.tensor(float(self.labels[image_filename[1:-4]]))\n",
    "\n",
    "        return combined_input, measurement_features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((1920, 1080)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# train_dataset = PotholeDataset(\n",
    "#     image_dir='./data/images/train',\n",
    "#     heatmap_dir='./data/heatmaps/train',\n",
    "#     measurement_features_file='./data/train_processed.json',\n",
    "#     labels=train_labels,\n",
    "#     transform=data_transforms\n",
    "# )\n",
    "\n",
    "# val_dataset = PotholeDataset(\n",
    "#     image_dir='./data/images/val',\n",
    "#     heatmap_dir='./data/heatmaps/val',\n",
    "#     measurement_features_file='./data/val_processed.json',\n",
    "#     labels=val_labels,\n",
    "#     transform=data_transforms\n",
    "# )\n",
    "\n",
    "combined_dataset = PotholeDataset(\n",
    "    image_dir='./data/images/combined',\n",
    "    heatmap_dir='./data/heatmaps/combined',\n",
    "    measurement_features_file='./data/combined_processed.json',\n",
    "    labels=combined_labels,\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "test_dataset = PotholeDataset(\n",
    "    image_dir='./data/images/test',\n",
    "    heatmap_dir='./data/heatmaps/test',\n",
    "    measurement_features_file='./data/test_processed.json',\n",
    "    labels=test_labels,\n",
    "    transform=data_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader objects\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32,\n",
    "#                           shuffle=False, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "combined_loader = DataLoader(combined_dataset, batch_size=32,\n",
    "                             shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,\n",
    "                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(combined_dataset))\n",
    "val_size = len(combined_dataset) - train_size\n",
    "\n",
    "# Split the combined dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader objects for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PotholeDepthEstimator(nn.Module):\n",
    "#     def __init__(self, num_measurement_features=4):\n",
    "#         super(PotholeDepthEstimator, self).__init__()\n",
    "\n",
    "#         # Load a pre-trained ResNet model\n",
    "#         self.resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "#         # Adjust the input layer to accept 4 channels (3 for RGB + 1 for heatmap)\n",
    "#         self.resnet.conv1 = nn.Conv2d(4, 64, kernel_size=(\n",
    "#             7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "#         # Replace the final fully connected layer to output a single value (regression)\n",
    "#         # self.resnet.fc = nn.Linear(\n",
    "#         #     self.resnet.fc.in_features + num_measurement_features, 1)\n",
    "\n",
    "#         # FC layer to process measurement features\n",
    "#         self.measurement_fc = nn.Linear(num_measurement_features, 32)\n",
    "\n",
    "#         # Adjust the final fully connected layer to handle the concatenated input\n",
    "#         self.resnet.fc = nn.Linear(self.resnet.fc.in_features + 32, 1)\n",
    "\n",
    "#     def forward(self, x, measurement_features):\n",
    "#         # Pass the combined input through the CNN\n",
    "#         x = self.resnet(x)\n",
    "\n",
    "#         # Pass the measurement features through a FC layer\n",
    "#         measurement_features = self.measurement_fc(measurement_features)\n",
    "\n",
    "#         # Concatenate the CNN output with the measurement features\n",
    "#         x = torch.cat([x, measurement_features], dim=0)\n",
    "\n",
    "#         # Final regression output\n",
    "#         output = self.resnet.fc(x)\n",
    "\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotholeDepthEstimator(nn.Module):\n",
    "    def __init__(self, num_measurement_features=12):\n",
    "        super(PotholeDepthEstimator, self).__init__()\n",
    "\n",
    "        # Load a pre-trained ResNet-152 model\n",
    "        self.resnet = models.resnet152(pretrained=True)\n",
    "\n",
    "        # Adjust the input layer to accept 4 channels (3 for RGB + 1 for heatmap)\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Freeze most of the ResNet layers\n",
    "        for param in list(self.resnet.parameters())[:-2]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "\n",
    "        # FC layer to process measurement features\n",
    "        self.measurement_fc = nn.Linear(num_measurement_features, 64)\n",
    "\n",
    "        # New fully connected layers for combined features\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(2048 + 64, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Flatten(0, -1)  # Flatten the last dimension\n",
    "        )\n",
    "\n",
    "    def forward(self, x, measurement_features):\n",
    "        # Pass the combined input through the CNN\n",
    "        x = self.resnet(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Pass the measurement features through a FC layer\n",
    "        measurement_features = self.measurement_fc(measurement_features)\n",
    "\n",
    "        # Concatenate the CNN output with the measurement features\n",
    "        combined = torch.cat([x, measurement_features], dim=1)\n",
    "\n",
    "        # Final regression output\n",
    "        output = self.fc_combined(combined)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deanbrand/Projects/SBH2024/RegressionLoop/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/deanbrand/Projects/SBH2024/RegressionLoop/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = PotholeDepthEstimator().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 750\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Input Shape: torch.Size([4, 1920, 1080])\n",
      "Measurement Features: tensor([0.0299, 0.0337, 0.0010, 0.4731, 1.0000, 0.3081, 1.0000, 0.8032, 0.0010,\n",
      "        0.0010, 0.0303, 0.0342])\n",
      "Target: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Debugging the Dataset\n",
    "dataset = PotholeDataset(\n",
    "    image_dir='./data/images/combined/',\n",
    "    heatmap_dir='./data/heatmaps/combined/',\n",
    "    measurement_features_file='./data/combined_processed.json',\n",
    "    labels=combined_labels,\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "# Test loading a single item\n",
    "# Load the first item\n",
    "combined_input, measurement_features, target = dataset[2]\n",
    "\n",
    "print(f\"Combined Input Shape: {combined_input.shape}\")\n",
    "print(f\"Measurement Features: {measurement_features}\")\n",
    "print(f\"Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training R²: -0.1036\n",
      "Epoch 1, Validation R²: -1.9564\n",
      "Epoch 1, Validation Loss: 0.4784\n",
      "\n",
      "Epoch 2, Training R²: -0.1089\n",
      "Epoch 2, Validation R²: -0.3870\n",
      "Epoch 2, Validation Loss: 0.2139\n",
      "\n",
      "Epoch 3, Training R²: 0.0337\n",
      "Epoch 3, Validation R²: -2.1803\n",
      "Epoch 3, Validation Loss: 0.5115\n",
      "\n",
      "Epoch 4, Training R²: 0.0670\n",
      "Epoch 4, Validation R²: -2.6849\n",
      "Epoch 4, Validation Loss: 0.5959\n",
      "\n",
      "Epoch 5, Training R²: 0.0024\n",
      "Epoch 5, Validation R²: 0.0307\n",
      "Epoch 5, Validation Loss: 0.1381\n",
      "\n",
      "Epoch 6, Training R²: -0.0434\n",
      "Epoch 6, Validation R²: -1.0642\n",
      "Epoch 6, Validation Loss: 0.3255\n",
      "\n",
      "Epoch 7, Training R²: 0.0986\n",
      "Epoch 7, Validation R²: -1.3688\n",
      "Epoch 7, Validation Loss: 0.3678\n",
      "\n",
      "Epoch 8, Training R²: 0.1786\n",
      "Epoch 8, Validation R²: -0.3790\n",
      "Epoch 8, Validation Loss: 0.1984\n",
      "\n",
      "Epoch 9, Training R²: 0.2109\n",
      "Epoch 9, Validation R²: -0.6153\n",
      "Epoch 9, Validation Loss: 0.2308\n",
      "\n",
      "Epoch 10, Training R²: 0.2892\n",
      "Epoch 10, Validation R²: -1.3518\n",
      "Epoch 10, Validation Loss: 0.3353\n",
      "\n",
      "Epoch 11, Training R²: 0.2779\n",
      "Epoch 11, Validation R²: -1.3059\n",
      "Epoch 11, Validation Loss: 0.3179\n",
      "\n",
      "Epoch 12, Training R²: 0.3071\n",
      "Epoch 12, Validation R²: -1.9822\n",
      "Epoch 12, Validation Loss: 0.4332\n",
      "\n",
      "Epoch 13, Training R²: 0.3423\n",
      "Epoch 13, Validation R²: -0.4947\n",
      "Epoch 13, Validation Loss: 0.2173\n",
      "\n",
      "Epoch 14, Training R²: 0.3167\n",
      "Epoch 14, Validation R²: -2.1481\n",
      "Epoch 14, Validation Loss: 0.4351\n",
      "\n",
      "Epoch 15, Training R²: 0.3572\n",
      "Epoch 15, Validation R²: -0.7384\n",
      "Epoch 15, Validation Loss: 0.2451\n",
      "\n",
      "Epoch 16, Training R²: 0.4441\n",
      "Epoch 16, Validation R²: -5.1504\n",
      "Epoch 16, Validation Loss: 0.9094\n",
      "\n",
      "Epoch 17, Training R²: 0.4405\n",
      "Epoch 17, Validation R²: -0.1950\n",
      "Epoch 17, Validation Loss: 0.1682\n",
      "\n",
      "Epoch 18, Training R²: 0.4216\n",
      "Epoch 18, Validation R²: -0.7210\n",
      "Epoch 18, Validation Loss: 0.2389\n",
      "\n",
      "Epoch 19, Training R²: 0.4084\n",
      "Epoch 19, Validation R²: -2.3853\n",
      "Epoch 19, Validation Loss: 0.4952\n",
      "\n",
      "Epoch 20, Training R²: 0.4798\n",
      "Epoch 20, Validation R²: -0.4229\n",
      "Epoch 20, Validation Loss: 0.2014\n",
      "\n",
      "Epoch 21, Training R²: 0.4906\n",
      "Epoch 21, Validation R²: -0.7928\n",
      "Epoch 21, Validation Loss: 0.2561\n",
      "\n",
      "Epoch 22, Training R²: 0.4990\n",
      "Epoch 22, Validation R²: -0.4656\n",
      "Epoch 22, Validation Loss: 0.2084\n",
      "\n",
      "Epoch 23, Training R²: 0.5101\n",
      "Epoch 23, Validation R²: -1.0281\n",
      "Epoch 23, Validation Loss: 0.2870\n",
      "\n",
      "Epoch 24, Training R²: 0.5117\n",
      "Epoch 24, Validation R²: -0.3926\n",
      "Epoch 24, Validation Loss: 0.1950\n",
      "\n",
      "Epoch 25, Training R²: 0.4689\n",
      "Epoch 25, Validation R²: -0.8743\n",
      "Epoch 25, Validation Loss: 0.2801\n",
      "\n",
      "Epoch 26, Training R²: 0.5511\n",
      "Epoch 26, Validation R²: -0.5981\n",
      "Epoch 26, Validation Loss: 0.2293\n",
      "\n",
      "Epoch 27, Training R²: 0.5669\n",
      "Epoch 27, Validation R²: 0.0285\n",
      "Epoch 27, Validation Loss: 0.1423\n",
      "\n",
      "Epoch 28, Training R²: 0.5946\n",
      "Epoch 28, Validation R²: -0.8730\n",
      "Epoch 28, Validation Loss: 0.2702\n",
      "\n",
      "Epoch 29, Training R²: 0.5508\n",
      "Epoch 29, Validation R²: -0.9520\n",
      "Epoch 29, Validation Loss: 0.3006\n",
      "\n",
      "Epoch 30, Training R²: 0.6250\n",
      "Epoch 30, Validation R²: 0.1993\n",
      "Epoch 30, Validation Loss: 0.1166\n",
      "\n",
      "Epoch 31, Training R²: 0.5238\n",
      "Epoch 31, Validation R²: 0.3079\n",
      "Epoch 31, Validation Loss: 0.1033\n",
      "\n",
      "Epoch 32, Training R²: 0.3880\n",
      "Epoch 32, Validation R²: -1.3210\n",
      "Epoch 32, Validation Loss: 0.3565\n",
      "\n",
      "Epoch 33, Training R²: 0.5555\n",
      "Epoch 33, Validation R²: -0.8235\n",
      "Epoch 33, Validation Loss: 0.2708\n",
      "\n",
      "Epoch 34, Training R²: 0.5555\n",
      "Epoch 34, Validation R²: -7.7951\n",
      "Epoch 34, Validation Loss: 1.3217\n",
      "\n",
      "Epoch 35, Training R²: 0.5036\n",
      "Epoch 35, Validation R²: -2.0424\n",
      "Epoch 35, Validation Loss: 0.4521\n",
      "\n",
      "Epoch 36, Training R²: 0.3715\n",
      "Epoch 36, Validation R²: -1.2220\n",
      "Epoch 36, Validation Loss: 0.3596\n",
      "\n",
      "Epoch 37, Training R²: 0.5484\n",
      "Epoch 37, Validation R²: -0.2389\n",
      "Epoch 37, Validation Loss: 0.1757\n",
      "\n",
      "Epoch 38, Training R²: 0.6072\n",
      "Epoch 38, Validation R²: -0.0383\n",
      "Epoch 38, Validation Loss: 0.1471\n",
      "\n",
      "Epoch 39, Training R²: 0.5866\n",
      "Epoch 39, Validation R²: 0.0256\n",
      "Epoch 39, Validation Loss: 0.1406\n",
      "\n",
      "Epoch 40, Training R²: 0.6404\n",
      "Epoch 40, Validation R²: -1.9992\n",
      "Epoch 40, Validation Loss: 0.4520\n",
      "\n",
      "Epoch 41, Training R²: 0.5730\n",
      "Epoch 41, Validation R²: -3.3836\n",
      "Epoch 41, Validation Loss: 0.6821\n",
      "\n",
      "Epoch 42, Training R²: 0.5529\n",
      "Epoch 42, Validation R²: -1.0720\n",
      "Epoch 42, Validation Loss: 0.3063\n",
      "\n",
      "Epoch 43, Training R²: 0.5613\n",
      "Epoch 43, Validation R²: -2.4911\n",
      "Epoch 43, Validation Loss: 0.5226\n",
      "\n",
      "Epoch 44, Training R²: 0.4216\n",
      "Epoch 44, Validation R²: -0.4759\n",
      "Epoch 44, Validation Loss: 0.2251\n",
      "\n",
      "Epoch 45, Training R²: 0.5776\n",
      "Epoch 45, Validation R²: -0.3423\n",
      "Epoch 45, Validation Loss: 0.1935\n",
      "\n",
      "Epoch 46, Training R²: 0.5872\n",
      "Epoch 46, Validation R²: 0.2528\n",
      "Epoch 46, Validation Loss: 0.1131\n",
      "\n",
      "Epoch 47, Training R²: 0.6244\n",
      "Epoch 47, Validation R²: 0.2096\n",
      "Epoch 47, Validation Loss: 0.1153\n",
      "\n",
      "Epoch 48, Training R²: 0.6032\n",
      "Epoch 48, Validation R²: -0.4172\n",
      "Epoch 48, Validation Loss: 0.2054\n",
      "\n",
      "Epoch 49, Training R²: 0.6860\n",
      "Epoch 49, Validation R²: 0.3187\n",
      "Epoch 49, Validation Loss: 0.1006\n",
      "\n",
      "Epoch 50, Training R²: 0.5383\n",
      "Epoch 50, Validation R²: 0.0891\n",
      "Epoch 50, Validation Loss: 0.1305\n",
      "\n",
      "Epoch 51, Training R²: 0.3214\n",
      "Epoch 51, Validation R²: 0.0962\n",
      "Epoch 51, Validation Loss: 0.1328\n",
      "\n",
      "Epoch 52, Training R²: 0.5507\n",
      "Epoch 52, Validation R²: 0.3072\n",
      "Epoch 52, Validation Loss: 0.1036\n",
      "\n",
      "Epoch 53, Training R²: 0.4751\n",
      "Epoch 53, Validation R²: -0.0381\n",
      "Epoch 53, Validation Loss: 0.1540\n",
      "\n",
      "Epoch 54, Training R²: 0.6367\n",
      "Epoch 54, Validation R²: 0.2292\n",
      "Epoch 54, Validation Loss: 0.1132\n",
      "\n",
      "Epoch 55, Training R²: 0.6739\n",
      "Epoch 55, Validation R²: -0.1006\n",
      "Epoch 55, Validation Loss: 0.1567\n",
      "\n",
      "Epoch 56, Training R²: 0.6406\n",
      "Epoch 56, Validation R²: 0.2183\n",
      "Epoch 56, Validation Loss: 0.1202\n",
      "\n",
      "Epoch 57, Training R²: 0.6866\n",
      "Epoch 57, Validation R²: 0.1948\n",
      "Epoch 57, Validation Loss: 0.1155\n",
      "\n",
      "Epoch 58, Training R²: 0.6477\n",
      "Epoch 58, Validation R²: 0.2763\n",
      "Epoch 58, Validation Loss: 0.1050\n",
      "\n",
      "Epoch 59, Training R²: 0.6168\n",
      "Epoch 59, Validation R²: -1.8950\n",
      "Epoch 59, Validation Loss: 0.4386\n",
      "\n",
      "Epoch 60, Training R²: 0.6200\n",
      "Epoch 60, Validation R²: -0.6382\n",
      "Epoch 60, Validation Loss: 0.2419\n",
      "\n",
      "Epoch 61, Training R²: 0.6781\n",
      "Epoch 61, Validation R²: 0.2533\n",
      "Epoch 61, Validation Loss: 0.1120\n",
      "\n",
      "Epoch 62, Training R²: 0.6189\n",
      "Epoch 62, Validation R²: -0.0378\n",
      "Epoch 62, Validation Loss: 0.1516\n",
      "\n",
      "Epoch 63, Training R²: 0.6737\n",
      "Epoch 63, Validation R²: 0.2059\n",
      "Epoch 63, Validation Loss: 0.1143\n",
      "\n",
      "Epoch 64, Training R²: 0.5558\n",
      "Epoch 64, Validation R²: -0.6577\n",
      "Epoch 64, Validation Loss: 0.2528\n",
      "\n",
      "Epoch 65, Training R²: 0.6336\n",
      "Epoch 65, Validation R²: 0.0581\n",
      "Epoch 65, Validation Loss: 0.1357\n",
      "\n",
      "Epoch 66, Training R²: 0.6876\n",
      "Epoch 66, Validation R²: 0.0425\n",
      "Epoch 66, Validation Loss: 0.1471\n",
      "\n",
      "Epoch 67, Training R²: 0.7392\n",
      "Epoch 67, Validation R²: 0.2357\n",
      "Epoch 67, Validation Loss: 0.1130\n",
      "\n",
      "Epoch 68, Training R²: 0.7358\n",
      "Epoch 68, Validation R²: 0.0666\n",
      "Epoch 68, Validation Loss: 0.1449\n",
      "\n",
      "Epoch 69, Training R²: 0.7319\n",
      "Epoch 69, Validation R²: 0.0926\n",
      "Epoch 69, Validation Loss: 0.1292\n",
      "\n",
      "Epoch 70, Training R²: 0.6927\n",
      "Epoch 70, Validation R²: 0.1355\n",
      "Epoch 70, Validation Loss: 0.1338\n",
      "\n",
      "Epoch 71, Training R²: 0.7224\n",
      "Epoch 71, Validation R²: -0.4230\n",
      "Epoch 71, Validation Loss: 0.2075\n",
      "\n",
      "Epoch 72, Training R²: 0.6849\n",
      "Epoch 72, Validation R²: -0.1550\n",
      "Epoch 72, Validation Loss: 0.1708\n",
      "\n",
      "Epoch 73, Training R²: 0.7519\n",
      "Epoch 73, Validation R²: 0.0301\n",
      "Epoch 73, Validation Loss: 0.1368\n",
      "\n",
      "Epoch 74, Training R²: 0.7785\n",
      "Epoch 74, Validation R²: -0.1120\n",
      "Epoch 74, Validation Loss: 0.1689\n",
      "\n",
      "Epoch 75, Training R²: 0.7278\n",
      "Epoch 75, Validation R²: 0.2070\n",
      "Epoch 75, Validation Loss: 0.1214\n",
      "\n",
      "Epoch 76, Training R²: 0.6668\n",
      "Epoch 76, Validation R²: 0.3062\n",
      "Epoch 76, Validation Loss: 0.1017\n",
      "\n",
      "Epoch 77, Training R²: 0.7339\n",
      "Epoch 77, Validation R²: 0.1403\n",
      "Epoch 77, Validation Loss: 0.1215\n",
      "\n",
      "Epoch 78, Training R²: 0.7442\n",
      "Epoch 78, Validation R²: 0.1819\n",
      "Epoch 78, Validation Loss: 0.1239\n",
      "\n",
      "Epoch 79, Training R²: 0.7436\n",
      "Epoch 79, Validation R²: -0.0408\n",
      "Epoch 79, Validation Loss: 0.1489\n",
      "\n",
      "Epoch 80, Training R²: 0.7753\n",
      "Epoch 80, Validation R²: 0.1216\n",
      "Epoch 80, Validation Loss: 0.1305\n",
      "\n",
      "Epoch 81, Training R²: 0.7690\n",
      "Epoch 81, Validation R²: -0.0938\n",
      "Epoch 81, Validation Loss: 0.1599\n",
      "\n",
      "Epoch 82, Training R²: 0.7807\n",
      "Epoch 82, Validation R²: 0.1920\n",
      "Epoch 82, Validation Loss: 0.1222\n",
      "\n",
      "Epoch 83, Training R²: 0.7721\n",
      "Epoch 83, Validation R²: 0.2596\n",
      "Epoch 83, Validation Loss: 0.1057\n",
      "\n",
      "Epoch 84, Training R²: 0.7828\n",
      "Epoch 84, Validation R²: 0.1905\n",
      "Epoch 84, Validation Loss: 0.1150\n",
      "\n",
      "Epoch 85, Training R²: 0.8112\n",
      "Epoch 85, Validation R²: -0.0336\n",
      "Epoch 85, Validation Loss: 0.1541\n",
      "\n",
      "Epoch 86, Training R²: 0.7775\n",
      "Epoch 86, Validation R²: 0.2557\n",
      "Epoch 86, Validation Loss: 0.1065\n",
      "\n",
      "Epoch 87, Training R²: 0.7577\n",
      "Epoch 87, Validation R²: 0.2518\n",
      "Epoch 87, Validation Loss: 0.1116\n",
      "\n",
      "Epoch 88, Training R²: 0.7357\n",
      "Epoch 88, Validation R²: -0.9087\n",
      "Epoch 88, Validation Loss: 0.2652\n",
      "\n",
      "Epoch 89, Training R²: 0.7043\n",
      "Epoch 89, Validation R²: -0.5138\n",
      "Epoch 89, Validation Loss: 0.2327\n",
      "\n",
      "Epoch 90, Training R²: 0.7887\n",
      "Epoch 90, Validation R²: -0.3451\n",
      "Epoch 90, Validation Loss: 0.1913\n",
      "\n",
      "Epoch 91, Training R²: 0.7851\n",
      "Epoch 91, Validation R²: 0.0102\n",
      "Epoch 91, Validation Loss: 0.1448\n",
      "\n",
      "Epoch 92, Training R²: 0.8114\n",
      "Epoch 92, Validation R²: 0.1717\n",
      "Epoch 92, Validation Loss: 0.1229\n",
      "\n",
      "Epoch 93, Training R²: 0.8090\n",
      "Epoch 93, Validation R²: 0.0421\n",
      "Epoch 93, Validation Loss: 0.1346\n",
      "\n",
      "Epoch 94, Training R²: 0.8094\n",
      "Epoch 94, Validation R²: -0.3943\n",
      "Epoch 94, Validation Loss: 0.2017\n",
      "\n",
      "Epoch 95, Training R²: 0.7607\n",
      "Epoch 95, Validation R²: -0.2313\n",
      "Epoch 95, Validation Loss: 0.1829\n",
      "\n",
      "Epoch 96, Training R²: 0.8343\n",
      "Epoch 96, Validation R²: -0.1368\n",
      "Epoch 96, Validation Loss: 0.1665\n",
      "\n",
      "Epoch 97, Training R²: 0.8176\n",
      "Epoch 97, Validation R²: 0.0733\n",
      "Epoch 97, Validation Loss: 0.1350\n",
      "\n",
      "Epoch 98, Training R²: 0.7934\n",
      "Epoch 98, Validation R²: -0.0891\n",
      "Epoch 98, Validation Loss: 0.1521\n",
      "\n",
      "Epoch 99, Training R²: 0.7834\n",
      "Epoch 99, Validation R²: 0.2366\n",
      "Epoch 99, Validation Loss: 0.1110\n",
      "\n",
      "Epoch 100, Training R²: 0.7938\n",
      "Epoch 100, Validation R²: 0.1645\n",
      "Epoch 100, Validation Loss: 0.1231\n",
      "\n",
      "Epoch 101, Training R²: 0.8073\n",
      "Epoch 101, Validation R²: 0.0859\n",
      "Epoch 101, Validation Loss: 0.1288\n",
      "\n",
      "Epoch 102, Training R²: 0.8056\n",
      "Epoch 102, Validation R²: -0.2301\n",
      "Epoch 102, Validation Loss: 0.1835\n",
      "\n",
      "Epoch 103, Training R²: 0.7481\n",
      "Epoch 103, Validation R²: 0.0991\n",
      "Epoch 103, Validation Loss: 0.1278\n",
      "\n",
      "Epoch 104, Training R²: 0.7008\n",
      "Epoch 104, Validation R²: -0.0420\n",
      "Epoch 104, Validation Loss: 0.1455\n",
      "\n",
      "Epoch 105, Training R²: 0.7423\n",
      "Epoch 105, Validation R²: -0.6833\n",
      "Epoch 105, Validation Loss: 0.2559\n",
      "\n",
      "Epoch 106, Training R²: 0.8100\n",
      "Epoch 106, Validation R²: 0.0815\n",
      "Epoch 106, Validation Loss: 0.1299\n",
      "\n",
      "Epoch 107, Training R²: 0.7876\n",
      "Epoch 107, Validation R²: -0.2654\n",
      "Epoch 107, Validation Loss: 0.1839\n",
      "\n",
      "Epoch 108, Training R²: 0.8189\n",
      "Epoch 108, Validation R²: -0.4348\n",
      "Epoch 108, Validation Loss: 0.2072\n",
      "\n",
      "Epoch 109, Training R²: 0.8224\n",
      "Epoch 109, Validation R²: -0.4808\n",
      "Epoch 109, Validation Loss: 0.2185\n",
      "\n",
      "Epoch 110, Training R²: 0.8154\n",
      "Epoch 110, Validation R²: 0.1253\n",
      "Epoch 110, Validation Loss: 0.1265\n",
      "\n",
      "Epoch 111, Training R²: 0.8300\n",
      "Epoch 111, Validation R²: 0.1553\n",
      "Epoch 111, Validation Loss: 0.1204\n",
      "\n",
      "Epoch 112, Training R²: 0.8405\n",
      "Epoch 112, Validation R²: -0.0016\n",
      "Epoch 112, Validation Loss: 0.1445\n",
      "\n",
      "Epoch 113, Training R²: 0.8513\n",
      "Epoch 113, Validation R²: -0.1880\n",
      "Epoch 113, Validation Loss: 0.1709\n",
      "\n",
      "Epoch 114, Training R²: 0.8485\n",
      "Epoch 114, Validation R²: 0.0124\n",
      "Epoch 114, Validation Loss: 0.1415\n",
      "\n",
      "Epoch 115, Training R²: 0.8549\n",
      "Epoch 115, Validation R²: 0.0975\n",
      "Epoch 115, Validation Loss: 0.1270\n",
      "\n",
      "Epoch 116, Training R²: 0.8540\n",
      "Epoch 116, Validation R²: 0.1470\n",
      "Epoch 116, Validation Loss: 0.1204\n",
      "\n",
      "Epoch 117, Training R²: 0.8372\n",
      "Epoch 117, Validation R²: -0.2486\n",
      "Epoch 117, Validation Loss: 0.1842\n",
      "\n",
      "Epoch 118, Training R²: 0.7991\n",
      "Epoch 118, Validation R²: 0.0204\n",
      "Epoch 118, Validation Loss: 0.1378\n",
      "\n",
      "Epoch 119, Training R²: 0.8106\n",
      "Epoch 119, Validation R²: -0.4906\n",
      "Epoch 119, Validation Loss: 0.2149\n",
      "\n",
      "Epoch 120, Training R²: 0.8182\n",
      "Epoch 120, Validation R²: -0.1039\n",
      "Epoch 120, Validation Loss: 0.1557\n",
      "\n",
      "Epoch 121, Training R²: 0.8413\n",
      "Epoch 121, Validation R²: -0.3645\n",
      "Epoch 121, Validation Loss: 0.1995\n",
      "\n",
      "Epoch 122, Training R²: 0.8286\n",
      "Epoch 122, Validation R²: -0.2269\n",
      "Epoch 122, Validation Loss: 0.1740\n",
      "\n",
      "Epoch 123, Training R²: 0.8448\n",
      "Epoch 123, Validation R²: -0.4208\n",
      "Epoch 123, Validation Loss: 0.2023\n",
      "\n",
      "Epoch 124, Training R²: 0.8610\n",
      "Epoch 124, Validation R²: -0.1514\n",
      "Epoch 124, Validation Loss: 0.1615\n",
      "\n",
      "Epoch 125, Training R²: 0.8534\n",
      "Epoch 125, Validation R²: 0.1256\n",
      "Epoch 125, Validation Loss: 0.1257\n",
      "\n",
      "Epoch 126, Training R²: 0.7769\n",
      "Epoch 126, Validation R²: -0.2425\n",
      "Epoch 126, Validation Loss: 0.1722\n",
      "\n",
      "Epoch 127, Training R²: 0.8249\n",
      "Epoch 127, Validation R²: -1.3324\n",
      "Epoch 127, Validation Loss: 0.3502\n",
      "\n",
      "Epoch 128, Training R²: 0.8105\n",
      "Epoch 128, Validation R²: -0.1772\n",
      "Epoch 128, Validation Loss: 0.1648\n",
      "\n",
      "Epoch 129, Training R²: 0.8316\n",
      "Epoch 129, Validation R²: 0.1192\n",
      "Epoch 129, Validation Loss: 0.1246\n",
      "\n",
      "Epoch 130, Training R²: 0.8323\n",
      "Epoch 130, Validation R²: 0.1827\n",
      "Epoch 130, Validation Loss: 0.1161\n",
      "\n",
      "Epoch 131, Training R²: 0.7709\n",
      "Epoch 131, Validation R²: -0.3571\n",
      "Epoch 131, Validation Loss: 0.1882\n",
      "\n",
      "Epoch 132, Training R²: 0.7230\n",
      "Epoch 132, Validation R²: -0.4948\n",
      "Epoch 132, Validation Loss: 0.2136\n",
      "\n",
      "Epoch 133, Training R²: 0.7150\n",
      "Epoch 133, Validation R²: -0.2659\n",
      "Epoch 133, Validation Loss: 0.1786\n",
      "\n",
      "Epoch 134, Training R²: 0.8263\n",
      "Epoch 134, Validation R²: -0.0070\n",
      "Epoch 134, Validation Loss: 0.1453\n",
      "\n",
      "Epoch 135, Training R²: 0.7172\n",
      "Epoch 135, Validation R²: -1.0349\n",
      "Epoch 135, Validation Loss: 0.2940\n",
      "\n",
      "Epoch 136, Training R²: 0.8137\n",
      "Epoch 136, Validation R²: -0.2351\n",
      "Epoch 136, Validation Loss: 0.1816\n",
      "\n",
      "Epoch 137, Training R²: 0.8518\n",
      "Epoch 137, Validation R²: 0.1863\n",
      "Epoch 137, Validation Loss: 0.1157\n",
      "\n",
      "Epoch 138, Training R²: 0.8659\n",
      "Epoch 138, Validation R²: -0.2830\n",
      "Epoch 138, Validation Loss: 0.1843\n",
      "\n",
      "Epoch 139, Training R²: 0.8648\n",
      "Epoch 139, Validation R²: 0.0817\n",
      "Epoch 139, Validation Loss: 0.1300\n",
      "\n",
      "Epoch 140, Training R²: 0.8289\n",
      "Epoch 140, Validation R²: 0.0725\n",
      "Epoch 140, Validation Loss: 0.1305\n",
      "\n",
      "Epoch 141, Training R²: 0.8234\n",
      "Epoch 141, Validation R²: -0.2101\n",
      "Epoch 141, Validation Loss: 0.1683\n",
      "\n",
      "Epoch 142, Training R²: 0.7957\n",
      "Epoch 142, Validation R²: -0.0676\n",
      "Epoch 142, Validation Loss: 0.1540\n",
      "\n",
      "Epoch 143, Training R²: 0.8508\n",
      "Epoch 143, Validation R²: 0.0846\n",
      "Epoch 143, Validation Loss: 0.1296\n",
      "\n",
      "Epoch 144, Training R²: 0.8552\n",
      "Epoch 144, Validation R²: -0.3426\n",
      "Epoch 144, Validation Loss: 0.1882\n",
      "\n",
      "Epoch 145, Training R²: 0.8211\n",
      "Epoch 145, Validation R²: -0.6054\n",
      "Epoch 145, Validation Loss: 0.2358\n",
      "\n",
      "Epoch 146, Training R²: 0.8061\n",
      "Epoch 146, Validation R²: 0.0333\n",
      "Epoch 146, Validation Loss: 0.1358\n",
      "\n",
      "Epoch 147, Training R²: 0.7979\n",
      "Epoch 147, Validation R²: 0.0639\n",
      "Epoch 147, Validation Loss: 0.1336\n",
      "\n",
      "Epoch 148, Training R²: 0.8453\n",
      "Epoch 148, Validation R²: -0.1207\n",
      "Epoch 148, Validation Loss: 0.1563\n",
      "\n",
      "Epoch 149, Training R²: 0.8466\n",
      "Epoch 149, Validation R²: -0.0937\n",
      "Epoch 149, Validation Loss: 0.1561\n",
      "\n",
      "Epoch 150, Training R²: 0.8397\n",
      "Epoch 150, Validation R²: -0.6063\n",
      "Epoch 150, Validation Loss: 0.2262\n",
      "\n",
      "Epoch 151, Training R²: 0.8349\n",
      "Epoch 151, Validation R²: -0.7956\n",
      "Epoch 151, Validation Loss: 0.2553\n",
      "\n",
      "Epoch 152, Training R²: 0.8345\n",
      "Epoch 152, Validation R²: -0.0116\n",
      "Epoch 152, Validation Loss: 0.1430\n",
      "\n",
      "Epoch 153, Training R²: 0.8290\n",
      "Epoch 153, Validation R²: -0.0821\n",
      "Epoch 153, Validation Loss: 0.1542\n",
      "\n",
      "Epoch 154, Training R²: 0.8085\n",
      "Epoch 154, Validation R²: -0.5607\n",
      "Epoch 154, Validation Loss: 0.2264\n",
      "\n",
      "Epoch 155, Training R²: 0.8608\n",
      "Epoch 155, Validation R²: -0.0635\n",
      "Epoch 155, Validation Loss: 0.1513\n",
      "\n",
      "Epoch 156, Training R²: 0.8833\n",
      "Epoch 156, Validation R²: 0.0939\n",
      "Epoch 156, Validation Loss: 0.1276\n",
      "\n",
      "Epoch 157, Training R²: 0.8589\n",
      "Epoch 157, Validation R²: -0.5601\n",
      "Epoch 157, Validation Loss: 0.2197\n",
      "\n",
      "Epoch 158, Training R²: 0.8642\n",
      "Epoch 158, Validation R²: -0.8888\n",
      "Epoch 158, Validation Loss: 0.2756\n",
      "\n",
      "Epoch 159, Training R²: 0.8563\n",
      "Epoch 159, Validation R²: 0.1088\n",
      "Epoch 159, Validation Loss: 0.1257\n",
      "\n",
      "Epoch 160, Training R²: 0.8850\n",
      "Epoch 160, Validation R²: 0.1342\n",
      "Epoch 160, Validation Loss: 0.1226\n",
      "\n",
      "Epoch 161, Training R²: 0.8761\n",
      "Epoch 161, Validation R²: -0.8209\n",
      "Epoch 161, Validation Loss: 0.2625\n",
      "\n",
      "Epoch 162, Training R²: 0.8790\n",
      "Epoch 162, Validation R²: -0.2551\n",
      "Epoch 162, Validation Loss: 0.1761\n",
      "\n",
      "Epoch 163, Training R²: 0.8883\n",
      "Epoch 163, Validation R²: -0.1985\n",
      "Epoch 163, Validation Loss: 0.1710\n",
      "\n",
      "Epoch 164, Training R²: 0.8866\n",
      "Epoch 164, Validation R²: -0.3907\n",
      "Epoch 164, Validation Loss: 0.1938\n",
      "\n",
      "Epoch 165, Training R²: 0.8607\n",
      "Epoch 165, Validation R²: -0.5384\n",
      "Epoch 165, Validation Loss: 0.2221\n",
      "\n",
      "Epoch 166, Training R²: 0.8575\n",
      "Epoch 166, Validation R²: -0.0677\n",
      "Epoch 166, Validation Loss: 0.1517\n",
      "\n",
      "Epoch 167, Training R²: 0.8419\n",
      "Epoch 167, Validation R²: 0.0879\n",
      "Epoch 167, Validation Loss: 0.1299\n",
      "\n",
      "Epoch 168, Training R²: 0.8125\n",
      "Epoch 168, Validation R²: -0.3162\n",
      "Epoch 168, Validation Loss: 0.1861\n",
      "\n",
      "Epoch 169, Training R²: 0.8269\n",
      "Epoch 169, Validation R²: -0.3224\n",
      "Epoch 169, Validation Loss: 0.1868\n",
      "\n",
      "Epoch 170, Training R²: 0.8591\n",
      "Epoch 170, Validation R²: 0.0971\n",
      "Epoch 170, Validation Loss: 0.1288\n",
      "\n",
      "Epoch 171, Training R²: 0.8731\n",
      "Epoch 171, Validation R²: -0.1258\n",
      "Epoch 171, Validation Loss: 0.1598\n",
      "\n",
      "Epoch 172, Training R²: 0.8739\n",
      "Epoch 172, Validation R²: -0.1363\n",
      "Epoch 172, Validation Loss: 0.1586\n",
      "\n",
      "Epoch 173, Training R²: 0.7626\n",
      "Epoch 173, Validation R²: 0.0835\n",
      "Epoch 173, Validation Loss: 0.1315\n",
      "\n",
      "Epoch 174, Training R²: 0.8452\n",
      "Epoch 174, Validation R²: 0.0393\n",
      "Epoch 174, Validation Loss: 0.1378\n",
      "\n",
      "Epoch 175, Training R²: 0.8677\n",
      "Epoch 175, Validation R²: -0.4052\n",
      "Epoch 175, Validation Loss: 0.2005\n",
      "\n",
      "Epoch 176, Training R²: 0.8123\n",
      "Epoch 176, Validation R²: -0.6404\n",
      "Epoch 176, Validation Loss: 0.2348\n",
      "\n",
      "Epoch 177, Training R²: 0.8447\n",
      "Epoch 177, Validation R²: -0.1535\n",
      "Epoch 177, Validation Loss: 0.1617\n",
      "\n",
      "Epoch 178, Training R²: 0.8853\n",
      "Epoch 178, Validation R²: -0.0887\n",
      "Epoch 178, Validation Loss: 0.1525\n",
      "\n",
      "Epoch 179, Training R²: 0.8861\n",
      "Epoch 179, Validation R²: -0.2535\n",
      "Epoch 179, Validation Loss: 0.1750\n",
      "\n",
      "Epoch 180, Training R²: 0.8459\n",
      "Epoch 180, Validation R²: -0.7976\n",
      "Epoch 180, Validation Loss: 0.2585\n",
      "\n",
      "Epoch 181, Training R²: 0.8768\n",
      "Epoch 181, Validation R²: 0.1839\n",
      "Epoch 181, Validation Loss: 0.1175\n",
      "\n",
      "Epoch 182, Training R²: 0.8490\n",
      "Epoch 182, Validation R²: -0.1011\n",
      "Epoch 182, Validation Loss: 0.1565\n",
      "\n",
      "Epoch 183, Training R²: 0.8131\n",
      "Epoch 183, Validation R²: -0.4088\n",
      "Epoch 183, Validation Loss: 0.1952\n",
      "\n",
      "Epoch 184, Training R²: 0.8136\n",
      "Epoch 184, Validation R²: -1.0990\n",
      "Epoch 184, Validation Loss: 0.3078\n",
      "\n",
      "Epoch 185, Training R²: 0.8477\n",
      "Epoch 185, Validation R²: -0.5405\n",
      "Epoch 185, Validation Loss: 0.2175\n",
      "\n",
      "Epoch 186, Training R²: 0.8538\n",
      "Epoch 186, Validation R²: -0.1029\n",
      "Epoch 186, Validation Loss: 0.1568\n",
      "\n",
      "Epoch 187, Training R²: 0.8166\n",
      "Epoch 187, Validation R²: -0.2584\n",
      "Epoch 187, Validation Loss: 0.1747\n",
      "\n",
      "Epoch 188, Training R²: 0.8791\n",
      "Epoch 188, Validation R²: -0.0513\n",
      "Epoch 188, Validation Loss: 0.1464\n",
      "\n",
      "Epoch 189, Training R²: 0.7461\n",
      "Epoch 189, Validation R²: 0.0281\n",
      "Epoch 189, Validation Loss: 0.1357\n",
      "\n",
      "Epoch 190, Training R²: 0.3961\n",
      "Epoch 190, Validation R²: -0.5765\n",
      "Epoch 190, Validation Loss: 0.2246\n",
      "\n",
      "Epoch 191, Training R²: 0.5823\n",
      "Epoch 191, Validation R²: 0.0506\n",
      "Epoch 191, Validation Loss: 0.1357\n",
      "\n",
      "Epoch 192, Training R²: 0.6205\n",
      "Epoch 192, Validation R²: -0.7195\n",
      "Epoch 192, Validation Loss: 0.2406\n",
      "\n",
      "Epoch 193, Training R²: 0.7081\n",
      "Epoch 193, Validation R²: -0.0422\n",
      "Epoch 193, Validation Loss: 0.1500\n",
      "\n",
      "Epoch 194, Training R²: 0.7842\n",
      "Epoch 194, Validation R²: -0.1778\n",
      "Epoch 194, Validation Loss: 0.1683\n",
      "\n",
      "Epoch 195, Training R²: 0.8598\n",
      "Epoch 195, Validation R²: -0.6752\n",
      "Epoch 195, Validation Loss: 0.2316\n",
      "\n",
      "Epoch 196, Training R²: 0.8140\n",
      "Epoch 196, Validation R²: -1.0611\n",
      "Epoch 196, Validation Loss: 0.2902\n",
      "\n",
      "Epoch 197, Training R²: 0.8810\n",
      "Epoch 197, Validation R²: -0.4929\n",
      "Epoch 197, Validation Loss: 0.2107\n",
      "\n",
      "Epoch 198, Training R²: 0.8687\n",
      "Epoch 198, Validation R²: -0.2253\n",
      "Epoch 198, Validation Loss: 0.1703\n",
      "\n",
      "Epoch 199, Training R²: 0.8804\n",
      "Epoch 199, Validation R²: -0.0348\n",
      "Epoch 199, Validation Loss: 0.1449\n",
      "\n",
      "Epoch 200, Training R²: 0.7938\n",
      "Epoch 200, Validation R²: -0.1578\n",
      "Epoch 200, Validation Loss: 0.1647\n",
      "\n",
      "Epoch 201, Training R²: 0.7590\n",
      "Epoch 201, Validation R²: -0.0844\n",
      "Epoch 201, Validation Loss: 0.1560\n",
      "\n",
      "Epoch 202, Training R²: 0.8191\n",
      "Epoch 202, Validation R²: -1.0707\n",
      "Epoch 202, Validation Loss: 0.2986\n",
      "\n",
      "Epoch 203, Training R²: 0.8141\n",
      "Epoch 203, Validation R²: -0.4233\n",
      "Epoch 203, Validation Loss: 0.1992\n",
      "\n",
      "Epoch 204, Training R²: 0.8557\n",
      "Epoch 204, Validation R²: -0.7655\n",
      "Epoch 204, Validation Loss: 0.2457\n",
      "\n",
      "Epoch 205, Training R²: 0.8569\n",
      "Epoch 205, Validation R²: -0.1401\n",
      "Epoch 205, Validation Loss: 0.1587\n",
      "\n",
      "Epoch 206, Training R²: 0.8859\n",
      "Epoch 206, Validation R²: -0.4826\n",
      "Epoch 206, Validation Loss: 0.2107\n",
      "\n",
      "Epoch 207, Training R²: 0.8909\n",
      "Epoch 207, Validation R²: -0.7906\n",
      "Epoch 207, Validation Loss: 0.2461\n",
      "\n",
      "Epoch 208, Training R²: 0.8756\n",
      "Epoch 208, Validation R²: -0.0880\n",
      "Epoch 208, Validation Loss: 0.1517\n",
      "\n",
      "Epoch 209, Training R²: 0.8892\n",
      "Epoch 209, Validation R²: -0.1561\n",
      "Epoch 209, Validation Loss: 0.1611\n",
      "\n",
      "Epoch 210, Training R²: 0.8766\n",
      "Epoch 210, Validation R²: -1.0249\n",
      "Epoch 210, Validation Loss: 0.2793\n",
      "\n",
      "Epoch 211, Training R²: 0.8890\n",
      "Epoch 211, Validation R²: -0.6022\n",
      "Epoch 211, Validation Loss: 0.2272\n",
      "\n",
      "Epoch 212, Training R²: 0.8934\n",
      "Epoch 212, Validation R²: -0.3522\n",
      "Epoch 212, Validation Loss: 0.1869\n",
      "\n",
      "Epoch 213, Training R²: 0.8628\n",
      "Epoch 213, Validation R²: 0.1106\n",
      "Epoch 213, Validation Loss: 0.1267\n",
      "\n",
      "Epoch 214, Training R²: 0.7824\n",
      "Epoch 214, Validation R²: -0.1766\n",
      "Epoch 214, Validation Loss: 0.1658\n",
      "\n",
      "Epoch 215, Training R²: 0.7721\n",
      "Epoch 215, Validation R²: -0.6467\n",
      "Epoch 215, Validation Loss: 0.2291\n",
      "\n",
      "Epoch 216, Training R²: 0.8575\n",
      "Epoch 216, Validation R²: -0.2644\n",
      "Epoch 216, Validation Loss: 0.1771\n",
      "\n",
      "Epoch 217, Training R²: 0.8942\n",
      "Epoch 217, Validation R²: -0.3906\n",
      "Epoch 217, Validation Loss: 0.1952\n",
      "\n",
      "Epoch 218, Training R²: 0.8880\n",
      "Epoch 218, Validation R²: -0.3111\n",
      "Epoch 218, Validation Loss: 0.1838\n",
      "\n",
      "Epoch 219, Training R²: 0.8990\n",
      "Epoch 219, Validation R²: -0.9735\n",
      "Epoch 219, Validation Loss: 0.2791\n",
      "\n",
      "Epoch 220, Training R²: 0.8710\n",
      "Epoch 220, Validation R²: -0.9949\n",
      "Epoch 220, Validation Loss: 0.2892\n",
      "\n",
      "Epoch 221, Training R²: 0.8675\n",
      "Epoch 221, Validation R²: -0.2070\n",
      "Epoch 221, Validation Loss: 0.1702\n",
      "\n",
      "Epoch 222, Training R²: 0.7978\n",
      "Epoch 222, Validation R²: -0.1549\n",
      "Epoch 222, Validation Loss: 0.1628\n",
      "\n",
      "Epoch 223, Training R²: 0.7834\n",
      "Epoch 223, Validation R²: -0.0405\n",
      "Epoch 223, Validation Loss: 0.1468\n",
      "\n",
      "Epoch 224, Training R²: 0.8495\n",
      "Epoch 224, Validation R²: -0.2275\n",
      "Epoch 224, Validation Loss: 0.1723\n",
      "\n",
      "Epoch 225, Training R²: 0.8403\n",
      "Epoch 225, Validation R²: -0.6668\n",
      "Epoch 225, Validation Loss: 0.2392\n",
      "\n",
      "Epoch 226, Training R²: 0.8627\n",
      "Epoch 226, Validation R²: -0.0958\n",
      "Epoch 226, Validation Loss: 0.1543\n",
      "\n",
      "Epoch 227, Training R²: 0.8848\n",
      "Epoch 227, Validation R²: 0.0615\n",
      "Epoch 227, Validation Loss: 0.1326\n",
      "\n",
      "Epoch 228, Training R²: 0.8327\n",
      "Epoch 228, Validation R²: -0.3975\n",
      "Epoch 228, Validation Loss: 0.1957\n",
      "\n",
      "Epoch 229, Training R²: 0.7973\n",
      "Epoch 229, Validation R²: -0.0607\n",
      "Epoch 229, Validation Loss: 0.1515\n",
      "\n",
      "Epoch 230, Training R²: 0.8754\n",
      "Epoch 230, Validation R²: -0.1107\n",
      "Epoch 230, Validation Loss: 0.1589\n",
      "\n",
      "Epoch 231, Training R²: 0.8933\n",
      "Epoch 231, Validation R²: -0.1820\n",
      "Epoch 231, Validation Loss: 0.1647\n",
      "\n",
      "Epoch 232, Training R²: 0.9032\n",
      "Epoch 232, Validation R²: -0.4443\n",
      "Epoch 232, Validation Loss: 0.2050\n",
      "\n",
      "Epoch 233, Training R²: 0.9093\n",
      "Epoch 233, Validation R²: -0.2974\n",
      "Epoch 233, Validation Loss: 0.1838\n",
      "\n",
      "Epoch 234, Training R²: 0.9138\n",
      "Epoch 234, Validation R²: -0.3548\n",
      "Epoch 234, Validation Loss: 0.1915\n",
      "\n",
      "Epoch 235, Training R²: 0.8980\n",
      "Epoch 235, Validation R²: -1.2199\n",
      "Epoch 235, Validation Loss: 0.3168\n",
      "\n",
      "Epoch 236, Training R²: 0.8668\n",
      "Epoch 236, Validation R²: -0.0284\n",
      "Epoch 236, Validation Loss: 0.1441\n",
      "\n",
      "Epoch 237, Training R²: 0.8808\n",
      "Epoch 237, Validation R²: 0.0109\n",
      "Epoch 237, Validation Loss: 0.1394\n",
      "\n",
      "Epoch 238, Training R²: 0.8906\n",
      "Epoch 238, Validation R²: -0.8938\n",
      "Epoch 238, Validation Loss: 0.2687\n",
      "\n",
      "Epoch 239, Training R²: 0.8979\n",
      "Epoch 239, Validation R²: -0.4382\n",
      "Epoch 239, Validation Loss: 0.1989\n",
      "\n",
      "Epoch 240, Training R²: 0.8784\n",
      "Epoch 240, Validation R²: -0.0234\n",
      "Epoch 240, Validation Loss: 0.1435\n",
      "\n",
      "Epoch 241, Training R²: 0.9133\n",
      "Epoch 241, Validation R²: -0.1170\n",
      "Epoch 241, Validation Loss: 0.1574\n",
      "\n",
      "Epoch 242, Training R²: 0.8926\n",
      "Epoch 242, Validation R²: -1.6898\n",
      "Epoch 242, Validation Loss: 0.3933\n",
      "\n",
      "Epoch 243, Training R²: 0.8951\n",
      "Epoch 243, Validation R²: 0.0853\n",
      "Epoch 243, Validation Loss: 0.1297\n",
      "\n",
      "Epoch 244, Training R²: 0.8955\n",
      "Epoch 244, Validation R²: -0.2212\n",
      "Epoch 244, Validation Loss: 0.1716\n",
      "\n",
      "Epoch 245, Training R²: 0.9167\n",
      "Epoch 245, Validation R²: -0.7540\n",
      "Epoch 245, Validation Loss: 0.2500\n",
      "\n",
      "Epoch 246, Training R²: 0.9032\n",
      "Epoch 246, Validation R²: -0.1163\n",
      "Epoch 246, Validation Loss: 0.1552\n",
      "\n",
      "Epoch 247, Training R²: 0.8841\n",
      "Epoch 247, Validation R²: -0.7399\n",
      "Epoch 247, Validation Loss: 0.2510\n",
      "\n",
      "Epoch 248, Training R²: 0.8976\n",
      "Epoch 248, Validation R²: -0.3407\n",
      "Epoch 248, Validation Loss: 0.1905\n",
      "\n",
      "Epoch 249, Training R²: 0.8955\n",
      "Epoch 249, Validation R²: -0.2324\n",
      "Epoch 249, Validation Loss: 0.1731\n",
      "\n",
      "Epoch 250, Training R²: 0.8910\n",
      "Epoch 250, Validation R²: -0.6959\n",
      "Epoch 250, Validation Loss: 0.2400\n",
      "\n",
      "Epoch 251, Training R²: 0.8570\n",
      "Epoch 251, Validation R²: -0.8923\n",
      "Epoch 251, Validation Loss: 0.2728\n",
      "\n",
      "Epoch 252, Training R²: 0.8311\n",
      "Epoch 252, Validation R²: -0.5370\n",
      "Epoch 252, Validation Loss: 0.2176\n",
      "\n",
      "Epoch 253, Training R²: 0.8886\n",
      "Epoch 253, Validation R²: -0.5609\n",
      "Epoch 253, Validation Loss: 0.2233\n",
      "\n",
      "Epoch 254, Training R²: 0.9087\n",
      "Epoch 254, Validation R²: -0.5874\n",
      "Epoch 254, Validation Loss: 0.2238\n",
      "\n",
      "Epoch 255, Training R²: 0.9012\n",
      "Epoch 255, Validation R²: 0.0704\n",
      "Epoch 255, Validation Loss: 0.1329\n",
      "\n",
      "Epoch 256, Training R²: 0.8854\n",
      "Epoch 256, Validation R²: -0.1326\n",
      "Epoch 256, Validation Loss: 0.1585\n",
      "\n",
      "Epoch 257, Training R²: 0.8705\n",
      "Epoch 257, Validation R²: -1.3380\n",
      "Epoch 257, Validation Loss: 0.3411\n",
      "\n",
      "Epoch 258, Training R²: 0.8491\n",
      "Epoch 258, Validation R²: 0.0002\n",
      "Epoch 258, Validation Loss: 0.1408\n",
      "\n",
      "Epoch 259, Training R²: 0.8001\n",
      "Epoch 259, Validation R²: -0.1104\n",
      "Epoch 259, Validation Loss: 0.1557\n",
      "\n",
      "Epoch 260, Training R²: 0.8808\n",
      "Epoch 260, Validation R²: -0.4517\n",
      "Epoch 260, Validation Loss: 0.2065\n",
      "\n",
      "Epoch 261, Training R²: 0.8969\n",
      "Epoch 261, Validation R²: -0.1355\n",
      "Epoch 261, Validation Loss: 0.1578\n",
      "\n",
      "Epoch 262, Training R²: 0.8758\n",
      "Epoch 262, Validation R²: -0.0334\n",
      "Epoch 262, Validation Loss: 0.1447\n",
      "\n",
      "Epoch 263, Training R²: 0.8427\n",
      "Epoch 263, Validation R²: -1.3306\n",
      "Epoch 263, Validation Loss: 0.3340\n",
      "\n",
      "Epoch 264, Training R²: 0.8799\n",
      "Epoch 264, Validation R²: -0.7396\n",
      "Epoch 264, Validation Loss: 0.2480\n",
      "\n",
      "Epoch 265, Training R²: 0.8604\n",
      "Epoch 265, Validation R²: -0.2024\n",
      "Epoch 265, Validation Loss: 0.1694\n",
      "\n",
      "Epoch 266, Training R²: 0.8908\n",
      "Epoch 266, Validation R²: -0.2206\n",
      "Epoch 266, Validation Loss: 0.1724\n",
      "\n",
      "Epoch 267, Training R²: 0.9132\n",
      "Epoch 267, Validation R²: -0.1544\n",
      "Epoch 267, Validation Loss: 0.1612\n",
      "\n",
      "Epoch 268, Training R²: 0.9145\n",
      "Epoch 268, Validation R²: -1.0191\n",
      "Epoch 268, Validation Loss: 0.2893\n",
      "\n",
      "Epoch 269, Training R²: 0.8675\n",
      "Epoch 269, Validation R²: -0.1820\n",
      "Epoch 269, Validation Loss: 0.1669\n",
      "\n",
      "Epoch 270, Training R²: 0.8663\n",
      "Epoch 270, Validation R²: 0.1331\n",
      "Epoch 270, Validation Loss: 0.1236\n",
      "\n",
      "Epoch 271, Training R²: 0.9084\n",
      "Epoch 271, Validation R²: -0.1819\n",
      "Epoch 271, Validation Loss: 0.1668\n",
      "\n",
      "Epoch 272, Training R²: 0.9022\n",
      "Epoch 272, Validation R²: -0.5192\n",
      "Epoch 272, Validation Loss: 0.2136\n",
      "\n",
      "Epoch 273, Training R²: 0.9087\n",
      "Epoch 273, Validation R²: -0.4156\n",
      "Epoch 273, Validation Loss: 0.1957\n",
      "\n",
      "Epoch 274, Training R²: 0.8998\n",
      "Epoch 274, Validation R²: -0.1917\n",
      "Epoch 274, Validation Loss: 0.1651\n",
      "\n",
      "Epoch 275, Training R²: 0.9151\n",
      "Epoch 275, Validation R²: -1.1042\n",
      "Epoch 275, Validation Loss: 0.3000\n",
      "\n",
      "Epoch 276, Training R²: 0.9042\n",
      "Epoch 276, Validation R²: -0.1945\n",
      "Epoch 276, Validation Loss: 0.1691\n",
      "\n",
      "Epoch 277, Training R²: 0.9129\n",
      "Epoch 277, Validation R²: -0.4511\n",
      "Epoch 277, Validation Loss: 0.2047\n",
      "\n",
      "Epoch 278, Training R²: 0.9088\n",
      "Epoch 278, Validation R²: -0.2048\n",
      "Epoch 278, Validation Loss: 0.1693\n",
      "\n",
      "Epoch 279, Training R²: 0.9154\n",
      "Epoch 279, Validation R²: -0.0470\n",
      "Epoch 279, Validation Loss: 0.1461\n",
      "\n",
      "Epoch 280, Training R²: 0.8977\n",
      "Epoch 280, Validation R²: 0.1046\n",
      "Epoch 280, Validation Loss: 0.1277\n",
      "\n",
      "Epoch 281, Training R²: 0.8526\n",
      "Epoch 281, Validation R²: -0.4689\n",
      "Epoch 281, Validation Loss: 0.2075\n",
      "\n",
      "Epoch 282, Training R²: 0.9217\n",
      "Epoch 282, Validation R²: -0.3817\n",
      "Epoch 282, Validation Loss: 0.1926\n",
      "\n",
      "Epoch 283, Training R²: 0.9179\n",
      "Epoch 283, Validation R²: -0.7202\n",
      "Epoch 283, Validation Loss: 0.2452\n",
      "\n",
      "Epoch 284, Training R²: 0.8976\n",
      "Epoch 284, Validation R²: -0.1862\n",
      "Epoch 284, Validation Loss: 0.1644\n",
      "\n",
      "Epoch 285, Training R²: 0.9212\n",
      "Epoch 285, Validation R²: 0.0762\n",
      "Epoch 285, Validation Loss: 0.1299\n",
      "\n",
      "Epoch 286, Training R²: 0.8967\n",
      "Epoch 286, Validation R²: -0.4231\n",
      "Epoch 286, Validation Loss: 0.2006\n",
      "\n",
      "Epoch 287, Training R²: 0.8948\n",
      "Epoch 287, Validation R²: -1.0502\n",
      "Epoch 287, Validation Loss: 0.2914\n",
      "\n",
      "Epoch 288, Training R²: 0.8909\n",
      "Epoch 288, Validation R²: -0.2750\n",
      "Epoch 288, Validation Loss: 0.1789\n",
      "\n",
      "Epoch 289, Training R²: 0.9083\n",
      "Epoch 289, Validation R²: -0.4508\n",
      "Epoch 289, Validation Loss: 0.2023\n",
      "\n",
      "Epoch 290, Training R²: 0.8985\n",
      "Epoch 290, Validation R²: -0.6041\n",
      "Epoch 290, Validation Loss: 0.2300\n",
      "\n",
      "Epoch 291, Training R²: 0.9084\n",
      "Epoch 291, Validation R²: -0.6873\n",
      "Epoch 291, Validation Loss: 0.2323\n",
      "\n",
      "Epoch 292, Training R²: 0.8942\n",
      "Epoch 292, Validation R²: -0.6308\n",
      "Epoch 292, Validation Loss: 0.2320\n",
      "\n",
      "Epoch 293, Training R²: 0.8792\n",
      "Epoch 293, Validation R²: -0.3812\n",
      "Epoch 293, Validation Loss: 0.1944\n",
      "\n",
      "Epoch 294, Training R²: 0.8964\n",
      "Epoch 294, Validation R²: -0.4744\n",
      "Epoch 294, Validation Loss: 0.2083\n",
      "\n",
      "Epoch 295, Training R²: 0.8740\n",
      "Epoch 295, Validation R²: -1.0921\n",
      "Epoch 295, Validation Loss: 0.3012\n",
      "\n",
      "Epoch 296, Training R²: 0.8335\n",
      "Epoch 296, Validation R²: -0.0560\n",
      "Epoch 296, Validation Loss: 0.1479\n",
      "\n",
      "Epoch 297, Training R²: 0.8980\n",
      "Epoch 297, Validation R²: -0.8960\n",
      "Epoch 297, Validation Loss: 0.2644\n",
      "\n",
      "Epoch 298, Training R²: 0.9160\n",
      "Epoch 298, Validation R²: -0.1693\n",
      "Epoch 298, Validation Loss: 0.1628\n",
      "\n",
      "Epoch 299, Training R²: 0.8928\n",
      "Epoch 299, Validation R²: -1.1062\n",
      "Epoch 299, Validation Loss: 0.3039\n",
      "\n",
      "Epoch 300, Training R²: 0.9010\n",
      "Epoch 300, Validation R²: -0.3194\n",
      "Epoch 300, Validation Loss: 0.1867\n",
      "\n",
      "Epoch 301, Training R²: 0.9100\n",
      "Epoch 301, Validation R²: -0.7723\n",
      "Epoch 301, Validation Loss: 0.2541\n",
      "\n",
      "Epoch 302, Training R²: 0.9175\n",
      "Epoch 302, Validation R²: 0.0768\n",
      "Epoch 302, Validation Loss: 0.1297\n",
      "\n",
      "Epoch 303, Training R²: 0.8672\n",
      "Epoch 303, Validation R²: -0.3382\n",
      "Epoch 303, Validation Loss: 0.1881\n",
      "\n",
      "Epoch 304, Training R²: 0.8828\n",
      "Epoch 304, Validation R²: -0.2099\n",
      "Epoch 304, Validation Loss: 0.1704\n",
      "\n",
      "Epoch 305, Training R²: 0.9010\n",
      "Epoch 305, Validation R²: -0.0434\n",
      "Epoch 305, Validation Loss: 0.1469\n",
      "\n",
      "Epoch 306, Training R²: 0.8987\n",
      "Epoch 306, Validation R²: -0.3976\n",
      "Epoch 306, Validation Loss: 0.1934\n",
      "\n",
      "Epoch 307, Training R²: 0.9001\n",
      "Epoch 307, Validation R²: -1.6707\n",
      "Epoch 307, Validation Loss: 0.3868\n",
      "\n",
      "Epoch 308, Training R²: 0.8464\n",
      "Epoch 308, Validation R²: 0.0056\n",
      "Epoch 308, Validation Loss: 0.1395\n",
      "\n",
      "Epoch 309, Training R²: 0.8917\n",
      "Epoch 309, Validation R²: -0.1370\n",
      "Epoch 309, Validation Loss: 0.1594\n",
      "\n",
      "Epoch 310, Training R²: 0.9106\n",
      "Epoch 310, Validation R²: -0.1178\n",
      "Epoch 310, Validation Loss: 0.1564\n",
      "\n",
      "Epoch 311, Training R²: 0.9090\n",
      "Epoch 311, Validation R²: 0.0806\n",
      "Epoch 311, Validation Loss: 0.1299\n",
      "\n",
      "Epoch 312, Training R²: 0.8985\n",
      "Epoch 312, Validation R²: -0.1604\n",
      "Epoch 312, Validation Loss: 0.1626\n",
      "\n",
      "Epoch 313, Training R²: 0.9087\n",
      "Epoch 313, Validation R²: -0.7067\n",
      "Epoch 313, Validation Loss: 0.2371\n",
      "\n",
      "Epoch 314, Training R²: 0.8361\n",
      "Epoch 314, Validation R²: -1.0287\n",
      "Epoch 314, Validation Loss: 0.2857\n",
      "\n",
      "Epoch 315, Training R²: 0.8697\n",
      "Epoch 315, Validation R²: -0.0766\n",
      "Epoch 315, Validation Loss: 0.1506\n",
      "\n",
      "Epoch 316, Training R²: 0.8720\n",
      "Epoch 316, Validation R²: 0.0133\n",
      "Epoch 316, Validation Loss: 0.1420\n",
      "\n",
      "Epoch 317, Training R²: 0.8670\n",
      "Epoch 317, Validation R²: -0.2863\n",
      "Epoch 317, Validation Loss: 0.1819\n",
      "\n",
      "Epoch 318, Training R²: 0.8941\n",
      "Epoch 318, Validation R²: -0.8341\n",
      "Epoch 318, Validation Loss: 0.2555\n",
      "\n",
      "Epoch 319, Training R²: 0.8152\n",
      "Epoch 319, Validation R²: -0.1515\n",
      "Epoch 319, Validation Loss: 0.1606\n",
      "\n",
      "Epoch 320, Training R²: 0.7515\n",
      "Epoch 320, Validation R²: -0.4637\n",
      "Epoch 320, Validation Loss: 0.2064\n",
      "\n",
      "Epoch 321, Training R²: 0.8416\n",
      "Epoch 321, Validation R²: -0.1027\n",
      "Epoch 321, Validation Loss: 0.1573\n",
      "\n",
      "Epoch 322, Training R²: 0.8865\n",
      "Epoch 322, Validation R²: -0.0729\n",
      "Epoch 322, Validation Loss: 0.1494\n",
      "\n",
      "Epoch 323, Training R²: 0.8848\n",
      "Epoch 323, Validation R²: -0.0986\n",
      "Epoch 323, Validation Loss: 0.1531\n",
      "\n",
      "Epoch 324, Training R²: 0.8627\n",
      "Epoch 324, Validation R²: -0.4421\n",
      "Epoch 324, Validation Loss: 0.2050\n",
      "\n",
      "Epoch 325, Training R²: 0.8663\n",
      "Epoch 325, Validation R²: -0.5807\n",
      "Epoch 325, Validation Loss: 0.2191\n",
      "\n",
      "Epoch 326, Training R²: 0.8872\n",
      "Epoch 326, Validation R²: -0.5252\n",
      "Epoch 326, Validation Loss: 0.2167\n",
      "\n",
      "Epoch 327, Training R²: 0.8651\n",
      "Epoch 327, Validation R²: -0.0550\n",
      "Epoch 327, Validation Loss: 0.1498\n",
      "\n",
      "Epoch 328, Training R²: 0.9078\n",
      "Epoch 328, Validation R²: -0.3183\n",
      "Epoch 328, Validation Loss: 0.1857\n",
      "\n",
      "Epoch 329, Training R²: 0.9088\n",
      "Epoch 329, Validation R²: -0.0803\n",
      "Epoch 329, Validation Loss: 0.1509\n",
      "\n",
      "Epoch 330, Training R²: 0.9118\n",
      "Epoch 330, Validation R²: -0.5320\n",
      "Epoch 330, Validation Loss: 0.2138\n",
      "\n",
      "Epoch 331, Training R²: 0.9195\n",
      "Epoch 331, Validation R²: -0.2667\n",
      "Epoch 331, Validation Loss: 0.1775\n",
      "\n",
      "Epoch 332, Training R²: 0.9070\n",
      "Epoch 332, Validation R²: -0.6373\n",
      "Epoch 332, Validation Loss: 0.2321\n",
      "\n",
      "Epoch 333, Training R²: 0.9110\n",
      "Epoch 333, Validation R²: -0.1893\n",
      "Epoch 333, Validation Loss: 0.1670\n",
      "\n",
      "Epoch 334, Training R²: 0.9164\n",
      "Epoch 334, Validation R²: -0.1879\n",
      "Epoch 334, Validation Loss: 0.1652\n",
      "\n",
      "Epoch 335, Training R²: 0.9108\n",
      "Epoch 335, Validation R²: -0.0586\n",
      "Epoch 335, Validation Loss: 0.1474\n",
      "\n",
      "Epoch 336, Training R²: 0.9303\n",
      "Epoch 336, Validation R²: -0.1227\n",
      "Epoch 336, Validation Loss: 0.1565\n",
      "\n",
      "Epoch 337, Training R²: 0.9010\n",
      "Epoch 337, Validation R²: -0.2011\n",
      "Epoch 337, Validation Loss: 0.1669\n",
      "\n",
      "Epoch 338, Training R²: 0.9197\n",
      "Epoch 338, Validation R²: -0.5101\n",
      "Epoch 338, Validation Loss: 0.2093\n",
      "\n",
      "Epoch 339, Training R²: 0.9235\n",
      "Epoch 339, Validation R²: -0.2094\n",
      "Epoch 339, Validation Loss: 0.1707\n",
      "\n",
      "Epoch 340, Training R²: 0.8871\n",
      "Epoch 340, Validation R²: -0.1147\n",
      "Epoch 340, Validation Loss: 0.1562\n",
      "\n",
      "Epoch 341, Training R²: 0.9161\n",
      "Epoch 341, Validation R²: -0.0949\n",
      "Epoch 341, Validation Loss: 0.1525\n",
      "\n",
      "Epoch 342, Training R²: 0.9211\n",
      "Epoch 342, Validation R²: -0.3272\n",
      "Epoch 342, Validation Loss: 0.1838\n",
      "\n",
      "Epoch 343, Training R²: 0.8526\n",
      "Epoch 343, Validation R²: -1.5372\n",
      "Epoch 343, Validation Loss: 0.3699\n",
      "\n",
      "Epoch 344, Training R²: 0.8324\n",
      "Epoch 344, Validation R²: -0.1262\n",
      "Epoch 344, Validation Loss: 0.1595\n",
      "\n",
      "Epoch 345, Training R²: 0.8906\n",
      "Epoch 345, Validation R²: -0.1293\n",
      "Epoch 345, Validation Loss: 0.1580\n",
      "\n",
      "Epoch 346, Training R²: 0.8513\n",
      "Epoch 346, Validation R²: -0.0567\n",
      "Epoch 346, Validation Loss: 0.1481\n",
      "\n",
      "Epoch 347, Training R²: 0.8916\n",
      "Epoch 347, Validation R²: -0.9862\n",
      "Epoch 347, Validation Loss: 0.2845\n",
      "\n",
      "Epoch 348, Training R²: 0.9015\n",
      "Epoch 348, Validation R²: -0.0269\n",
      "Epoch 348, Validation Loss: 0.1437\n",
      "\n",
      "Epoch 349, Training R²: 0.9079\n",
      "Epoch 349, Validation R²: -0.2199\n",
      "Epoch 349, Validation Loss: 0.1699\n",
      "\n",
      "Epoch 350, Training R²: 0.9207\n",
      "Epoch 350, Validation R²: -0.1840\n",
      "Epoch 350, Validation Loss: 0.1674\n",
      "\n",
      "Epoch 351, Training R²: 0.8996\n",
      "Epoch 351, Validation R²: 0.0337\n",
      "Epoch 351, Validation Loss: 0.1370\n",
      "\n",
      "Epoch 352, Training R²: 0.8976\n",
      "Epoch 352, Validation R²: -0.4029\n",
      "Epoch 352, Validation Loss: 0.1999\n",
      "\n",
      "Epoch 353, Training R²: 0.9250\n",
      "Epoch 353, Validation R²: -0.0711\n",
      "Epoch 353, Validation Loss: 0.1497\n",
      "\n",
      "Epoch 354, Training R²: 0.9008\n",
      "Epoch 354, Validation R²: -0.0092\n",
      "Epoch 354, Validation Loss: 0.1415\n",
      "\n",
      "Epoch 355, Training R²: 0.9071\n",
      "Epoch 355, Validation R²: 0.0072\n",
      "Epoch 355, Validation Loss: 0.1386\n",
      "\n",
      "Epoch 356, Training R²: 0.9164\n",
      "Epoch 356, Validation R²: -0.1659\n",
      "Epoch 356, Validation Loss: 0.1642\n",
      "\n",
      "Epoch 357, Training R²: 0.9302\n",
      "Epoch 357, Validation R²: -0.3327\n",
      "Epoch 357, Validation Loss: 0.1877\n",
      "\n",
      "Epoch 358, Training R²: 0.8897\n",
      "Epoch 358, Validation R²: -0.6067\n",
      "Epoch 358, Validation Loss: 0.2250\n",
      "\n",
      "Epoch 359, Training R²: 0.8954\n",
      "Epoch 359, Validation R²: -0.3133\n",
      "Epoch 359, Validation Loss: 0.1875\n",
      "\n",
      "Epoch 360, Training R²: 0.9124\n",
      "Epoch 360, Validation R²: -0.1488\n",
      "Epoch 360, Validation Loss: 0.1605\n",
      "\n",
      "Epoch 361, Training R²: 0.9334\n",
      "Epoch 361, Validation R²: -0.1763\n",
      "Epoch 361, Validation Loss: 0.1642\n",
      "\n",
      "Epoch 362, Training R²: 0.9358\n",
      "Epoch 362, Validation R²: -0.1615\n",
      "Epoch 362, Validation Loss: 0.1624\n",
      "\n",
      "Epoch 363, Training R²: 0.9336\n",
      "Epoch 363, Validation R²: -0.0440\n",
      "Epoch 363, Validation Loss: 0.1460\n",
      "\n",
      "Epoch 364, Training R²: 0.9323\n",
      "Epoch 364, Validation R²: -0.1125\n",
      "Epoch 364, Validation Loss: 0.1567\n",
      "\n",
      "Epoch 365, Training R²: 0.9368\n",
      "Epoch 365, Validation R²: -0.1864\n",
      "Epoch 365, Validation Loss: 0.1656\n",
      "\n",
      "Epoch 366, Training R²: 0.9198\n",
      "Epoch 366, Validation R²: -1.3521\n",
      "Epoch 366, Validation Loss: 0.3384\n",
      "\n",
      "Epoch 367, Training R²: 0.8878\n",
      "Epoch 367, Validation R²: 0.1108\n",
      "Epoch 367, Validation Loss: 0.1278\n",
      "\n",
      "Epoch 368, Training R²: 0.9169\n",
      "Epoch 368, Validation R²: -0.8497\n",
      "Epoch 368, Validation Loss: 0.2608\n",
      "\n",
      "Epoch 369, Training R²: 0.8981\n",
      "Epoch 369, Validation R²: -1.3600\n",
      "Epoch 369, Validation Loss: 0.3377\n",
      "\n",
      "Epoch 370, Training R²: 0.8735\n",
      "Epoch 370, Validation R²: -0.7005\n",
      "Epoch 370, Validation Loss: 0.2449\n",
      "\n",
      "Epoch 371, Training R²: 0.8783\n",
      "Epoch 371, Validation R²: -0.7940\n",
      "Epoch 371, Validation Loss: 0.2545\n",
      "\n",
      "Epoch 372, Training R²: 0.8776\n",
      "Epoch 372, Validation R²: -0.5191\n",
      "Epoch 372, Validation Loss: 0.2110\n",
      "\n",
      "Epoch 373, Training R²: 0.8898\n",
      "Epoch 373, Validation R²: -0.8496\n",
      "Epoch 373, Validation Loss: 0.2570\n",
      "\n",
      "Epoch 374, Training R²: 0.9101\n",
      "Epoch 374, Validation R²: -0.5987\n",
      "Epoch 374, Validation Loss: 0.2234\n",
      "\n",
      "Epoch 375, Training R²: 0.8545\n",
      "Epoch 375, Validation R²: -0.2631\n",
      "Epoch 375, Validation Loss: 0.1797\n",
      "\n",
      "Epoch 376, Training R²: 0.8949\n",
      "Epoch 376, Validation R²: -0.0090\n",
      "Epoch 376, Validation Loss: 0.1413\n",
      "\n",
      "Epoch 377, Training R²: 0.8870\n",
      "Epoch 377, Validation R²: -0.1877\n",
      "Epoch 377, Validation Loss: 0.1693\n",
      "\n",
      "Epoch 378, Training R²: 0.9112\n",
      "Epoch 378, Validation R²: -0.6656\n",
      "Epoch 378, Validation Loss: 0.2348\n",
      "\n",
      "Epoch 379, Training R²: 0.9055\n",
      "Epoch 379, Validation R²: -0.5596\n",
      "Epoch 379, Validation Loss: 0.2215\n",
      "\n",
      "Epoch 380, Training R²: 0.9248\n",
      "Epoch 380, Validation R²: -0.2824\n",
      "Epoch 380, Validation Loss: 0.1798\n",
      "\n",
      "Epoch 381, Training R²: 0.9255\n",
      "Epoch 381, Validation R²: -0.4614\n",
      "Epoch 381, Validation Loss: 0.2028\n",
      "\n",
      "Epoch 382, Training R²: 0.9166\n",
      "Epoch 382, Validation R²: -0.6976\n",
      "Epoch 382, Validation Loss: 0.2368\n",
      "\n",
      "Epoch 383, Training R²: 0.9117\n",
      "Epoch 383, Validation R²: -0.0685\n",
      "Epoch 383, Validation Loss: 0.1487\n",
      "\n",
      "Epoch 384, Training R²: 0.8769\n",
      "Epoch 384, Validation R²: -0.2699\n",
      "Epoch 384, Validation Loss: 0.1770\n",
      "\n",
      "Epoch 385, Training R²: 0.8715\n",
      "Epoch 385, Validation R²: 0.0270\n",
      "Epoch 385, Validation Loss: 0.1396\n",
      "\n",
      "Epoch 386, Training R²: 0.8820\n",
      "Epoch 386, Validation R²: -0.5748\n",
      "Epoch 386, Validation Loss: 0.2239\n",
      "\n",
      "Epoch 387, Training R²: 0.9341\n",
      "Epoch 387, Validation R²: -0.0248\n",
      "Epoch 387, Validation Loss: 0.1433\n",
      "\n",
      "Epoch 388, Training R²: 0.9313\n",
      "Epoch 388, Validation R²: -0.7016\n",
      "Epoch 388, Validation Loss: 0.2432\n",
      "\n",
      "Epoch 389, Training R²: 0.9048\n",
      "Epoch 389, Validation R²: -0.5791\n",
      "Epoch 389, Validation Loss: 0.2231\n",
      "\n",
      "Epoch 390, Training R²: 0.9058\n",
      "Epoch 390, Validation R²: -0.1825\n",
      "Epoch 390, Validation Loss: 0.1654\n",
      "\n",
      "Epoch 391, Training R²: 0.9289\n",
      "Epoch 391, Validation R²: -0.9338\n",
      "Epoch 391, Validation Loss: 0.2690\n",
      "\n",
      "Epoch 392, Training R²: 0.9066\n",
      "Epoch 392, Validation R²: -0.5779\n",
      "Epoch 392, Validation Loss: 0.2224\n",
      "\n",
      "Epoch 393, Training R²: 0.8932\n",
      "Epoch 393, Validation R²: 0.0412\n",
      "Epoch 393, Validation Loss: 0.1373\n",
      "\n",
      "Epoch 394, Training R²: 0.8955\n",
      "Epoch 394, Validation R²: -0.3682\n",
      "Epoch 394, Validation Loss: 0.1945\n",
      "\n",
      "Epoch 395, Training R²: 0.9063\n",
      "Epoch 395, Validation R²: -0.6441\n",
      "Epoch 395, Validation Loss: 0.2324\n",
      "\n",
      "Epoch 396, Training R²: 0.8730\n",
      "Epoch 396, Validation R²: -0.0519\n",
      "Epoch 396, Validation Loss: 0.1466\n",
      "\n",
      "Epoch 397, Training R²: 0.9352\n",
      "Epoch 397, Validation R²: -0.0370\n",
      "Epoch 397, Validation Loss: 0.1448\n",
      "\n",
      "Epoch 398, Training R²: 0.9077\n",
      "Epoch 398, Validation R²: -1.3796\n",
      "Epoch 398, Validation Loss: 0.3369\n",
      "\n",
      "Epoch 399, Training R²: 0.8955\n",
      "Epoch 399, Validation R²: -0.3169\n",
      "Epoch 399, Validation Loss: 0.1858\n",
      "\n",
      "Epoch 400, Training R²: 0.9228\n",
      "Epoch 400, Validation R²: 0.1412\n",
      "Epoch 400, Validation Loss: 0.1213\n",
      "\n",
      "Epoch 401, Training R²: 0.9269\n",
      "Epoch 401, Validation R²: -0.4199\n",
      "Epoch 401, Validation Loss: 0.2019\n",
      "\n",
      "Epoch 402, Training R²: 0.9107\n",
      "Epoch 402, Validation R²: -0.3062\n",
      "Epoch 402, Validation Loss: 0.1827\n",
      "\n",
      "Epoch 403, Training R²: 0.9217\n",
      "Epoch 403, Validation R²: -1.1407\n",
      "Epoch 403, Validation Loss: 0.3038\n",
      "\n",
      "Epoch 404, Training R²: 0.8981\n",
      "Epoch 404, Validation R²: 0.0174\n",
      "Epoch 404, Validation Loss: 0.1375\n",
      "\n",
      "Epoch 405, Training R²: 0.9365\n",
      "Epoch 405, Validation R²: -0.1371\n",
      "Epoch 405, Validation Loss: 0.1588\n",
      "\n",
      "Epoch 406, Training R²: 0.9292\n",
      "Epoch 406, Validation R²: -0.1944\n",
      "Epoch 406, Validation Loss: 0.1676\n",
      "\n",
      "Epoch 407, Training R²: 0.9103\n",
      "Epoch 407, Validation R²: -0.3283\n",
      "Epoch 407, Validation Loss: 0.1880\n",
      "\n",
      "Epoch 408, Training R²: 0.9019\n",
      "Epoch 408, Validation R²: 0.1080\n",
      "Epoch 408, Validation Loss: 0.1288\n",
      "\n",
      "Epoch 409, Training R²: 0.9018\n",
      "Epoch 409, Validation R²: 0.0471\n",
      "Epoch 409, Validation Loss: 0.1332\n",
      "\n",
      "Epoch 410, Training R²: 0.8613\n",
      "Epoch 410, Validation R²: -0.3244\n",
      "Epoch 410, Validation Loss: 0.1871\n",
      "\n",
      "Epoch 411, Training R²: 0.9077\n",
      "Epoch 411, Validation R²: 0.0219\n",
      "Epoch 411, Validation Loss: 0.1374\n",
      "\n",
      "Epoch 412, Training R²: 0.9352\n",
      "Epoch 412, Validation R²: -0.0360\n",
      "Epoch 412, Validation Loss: 0.1445\n",
      "\n",
      "Epoch 413, Training R²: 0.9148\n",
      "Epoch 413, Validation R²: 0.0111\n",
      "Epoch 413, Validation Loss: 0.1386\n",
      "\n",
      "Epoch 414, Training R²: 0.9106\n",
      "Epoch 414, Validation R²: 0.0087\n",
      "Epoch 414, Validation Loss: 0.1384\n",
      "\n",
      "Epoch 415, Training R²: 0.8941\n",
      "Epoch 415, Validation R²: -0.4518\n",
      "Epoch 415, Validation Loss: 0.2025\n",
      "\n",
      "Epoch 416, Training R²: 0.9213\n",
      "Epoch 416, Validation R²: -0.2566\n",
      "Epoch 416, Validation Loss: 0.1755\n",
      "\n",
      "Epoch 417, Training R²: 0.8687\n",
      "Epoch 417, Validation R²: -0.7045\n",
      "Epoch 417, Validation Loss: 0.2342\n",
      "\n",
      "Epoch 418, Training R²: 0.8591\n",
      "Epoch 418, Validation R²: -0.3186\n",
      "Epoch 418, Validation Loss: 0.1850\n",
      "\n",
      "Epoch 419, Training R²: 0.9081\n",
      "Epoch 419, Validation R²: -0.3653\n",
      "Epoch 419, Validation Loss: 0.1887\n",
      "\n",
      "Epoch 420, Training R²: 0.9056\n",
      "Epoch 420, Validation R²: -0.5335\n",
      "Epoch 420, Validation Loss: 0.2143\n",
      "\n",
      "Epoch 421, Training R²: 0.9210\n",
      "Epoch 421, Validation R²: -0.1288\n",
      "Epoch 421, Validation Loss: 0.1599\n",
      "\n",
      "Epoch 422, Training R²: 0.9202\n",
      "Epoch 422, Validation R²: 0.0281\n",
      "Epoch 422, Validation Loss: 0.1357\n",
      "\n",
      "Epoch 423, Training R²: 0.8749\n",
      "Epoch 423, Validation R²: -0.3700\n",
      "Epoch 423, Validation Loss: 0.1899\n",
      "\n",
      "Epoch 424, Training R²: 0.9056\n",
      "Epoch 424, Validation R²: -0.4888\n",
      "Epoch 424, Validation Loss: 0.2088\n",
      "\n",
      "Epoch 425, Training R²: 0.9320\n",
      "Epoch 425, Validation R²: -0.0262\n",
      "Epoch 425, Validation Loss: 0.1431\n",
      "\n",
      "Epoch 426, Training R²: 0.9158\n",
      "Epoch 426, Validation R²: 0.0379\n",
      "Epoch 426, Validation Loss: 0.1349\n",
      "\n",
      "Epoch 427, Training R²: 0.9328\n",
      "Epoch 427, Validation R²: 0.0810\n",
      "Epoch 427, Validation Loss: 0.1290\n",
      "\n",
      "Epoch 428, Training R²: 0.8797\n",
      "Epoch 428, Validation R²: -0.8255\n",
      "Epoch 428, Validation Loss: 0.2549\n",
      "\n",
      "Epoch 429, Training R²: 0.8912\n",
      "Epoch 429, Validation R²: -0.4109\n",
      "Epoch 429, Validation Loss: 0.1980\n",
      "\n",
      "Epoch 430, Training R²: 0.8512\n",
      "Epoch 430, Validation R²: -1.7193\n",
      "Epoch 430, Validation Loss: 0.3893\n",
      "\n",
      "Epoch 431, Training R²: 0.8224\n",
      "Epoch 431, Validation R²: 0.0742\n",
      "Epoch 431, Validation Loss: 0.1317\n",
      "\n",
      "Epoch 432, Training R²: 0.8838\n",
      "Epoch 432, Validation R²: 0.0352\n",
      "Epoch 432, Validation Loss: 0.1363\n",
      "\n",
      "Epoch 433, Training R²: 0.8790\n",
      "Epoch 433, Validation R²: -0.2527\n",
      "Epoch 433, Validation Loss: 0.1749\n",
      "\n",
      "Epoch 434, Training R²: 0.8814\n",
      "Epoch 434, Validation R²: -1.1477\n",
      "Epoch 434, Validation Loss: 0.3039\n",
      "\n",
      "Epoch 435, Training R²: 0.8597\n",
      "Epoch 435, Validation R²: 0.0887\n",
      "Epoch 435, Validation Loss: 0.1279\n",
      "\n",
      "Epoch 436, Training R²: 0.9105\n",
      "Epoch 436, Validation R²: -0.0039\n",
      "Epoch 436, Validation Loss: 0.1422\n",
      "\n",
      "Epoch 437, Training R²: 0.9309\n",
      "Epoch 437, Validation R²: -0.1805\n",
      "Epoch 437, Validation Loss: 0.1655\n",
      "\n",
      "Epoch 438, Training R²: 0.9137\n",
      "Epoch 438, Validation R²: -0.3054\n",
      "Epoch 438, Validation Loss: 0.1812\n",
      "\n",
      "Epoch 439, Training R²: 0.8942\n",
      "Epoch 439, Validation R²: -0.3276\n",
      "Epoch 439, Validation Loss: 0.1894\n",
      "\n",
      "Epoch 440, Training R²: 0.9085\n",
      "Epoch 440, Validation R²: -0.5103\n",
      "Epoch 440, Validation Loss: 0.2107\n",
      "\n",
      "Epoch 441, Training R²: 0.9311\n",
      "Epoch 441, Validation R²: -0.1776\n",
      "Epoch 441, Validation Loss: 0.1629\n",
      "\n",
      "Epoch 442, Training R²: 0.9126\n",
      "Epoch 442, Validation R²: -0.0384\n",
      "Epoch 442, Validation Loss: 0.1446\n",
      "\n",
      "Epoch 443, Training R²: 0.8940\n",
      "Epoch 443, Validation R²: 0.0539\n",
      "Epoch 443, Validation Loss: 0.1331\n",
      "\n",
      "Epoch 444, Training R²: 0.9097\n",
      "Epoch 444, Validation R²: -0.0758\n",
      "Epoch 444, Validation Loss: 0.1517\n",
      "\n",
      "Epoch 445, Training R²: 0.9366\n",
      "Epoch 445, Validation R²: -0.4662\n",
      "Epoch 445, Validation Loss: 0.2049\n",
      "\n",
      "Epoch 446, Training R²: 0.9271\n",
      "Epoch 446, Validation R²: -0.2554\n",
      "Epoch 446, Validation Loss: 0.1754\n",
      "\n",
      "Epoch 447, Training R²: 0.9249\n",
      "Epoch 447, Validation R²: -0.0960\n",
      "Epoch 447, Validation Loss: 0.1528\n",
      "\n",
      "Epoch 448, Training R²: 0.9184\n",
      "Epoch 448, Validation R²: 0.0513\n",
      "Epoch 448, Validation Loss: 0.1327\n",
      "\n",
      "Epoch 449, Training R²: 0.9201\n",
      "Epoch 449, Validation R²: -0.5573\n",
      "Epoch 449, Validation Loss: 0.2138\n",
      "\n",
      "Epoch 450, Training R²: 0.8711\n",
      "Epoch 450, Validation R²: -0.3548\n",
      "Epoch 450, Validation Loss: 0.1907\n",
      "\n",
      "Epoch 451, Training R²: 0.9144\n",
      "Epoch 451, Validation R²: 0.0015\n",
      "Epoch 451, Validation Loss: 0.1398\n",
      "\n",
      "Epoch 452, Training R²: 0.9454\n",
      "Epoch 452, Validation R²: 0.0111\n",
      "Epoch 452, Validation Loss: 0.1380\n",
      "\n",
      "Epoch 453, Training R²: 0.9343\n",
      "Epoch 453, Validation R²: -0.5520\n",
      "Epoch 453, Validation Loss: 0.2167\n",
      "\n",
      "Epoch 454, Training R²: 0.9399\n",
      "Epoch 454, Validation R²: -0.0046\n",
      "Epoch 454, Validation Loss: 0.1403\n",
      "\n",
      "Epoch 455, Training R²: 0.9436\n",
      "Epoch 455, Validation R²: -0.1258\n",
      "Epoch 455, Validation Loss: 0.1569\n",
      "\n",
      "Epoch 456, Training R²: 0.9296\n",
      "Epoch 456, Validation R²: -0.2170\n",
      "Epoch 456, Validation Loss: 0.1713\n",
      "\n",
      "Epoch 457, Training R²: 0.9333\n",
      "Epoch 457, Validation R²: -0.1473\n",
      "Epoch 457, Validation Loss: 0.1592\n",
      "\n",
      "Epoch 458, Training R²: 0.9331\n",
      "Epoch 458, Validation R²: -0.0798\n",
      "Epoch 458, Validation Loss: 0.1502\n",
      "\n",
      "Epoch 459, Training R²: 0.9146\n",
      "Epoch 459, Validation R²: 0.1123\n",
      "Epoch 459, Validation Loss: 0.1254\n",
      "\n",
      "Epoch 460, Training R²: 0.9091\n",
      "Epoch 460, Validation R²: -0.5472\n",
      "Epoch 460, Validation Loss: 0.2205\n",
      "\n",
      "Epoch 461, Training R²: 0.9179\n",
      "Epoch 461, Validation R²: -0.0098\n",
      "Epoch 461, Validation Loss: 0.1408\n",
      "\n",
      "Epoch 462, Training R²: 0.9241\n",
      "Epoch 462, Validation R²: -0.2850\n",
      "Epoch 462, Validation Loss: 0.1783\n",
      "\n",
      "Epoch 463, Training R²: 0.9439\n",
      "Epoch 463, Validation R²: -0.0889\n",
      "Epoch 463, Validation Loss: 0.1525\n",
      "\n",
      "Epoch 464, Training R²: 0.9438\n",
      "Epoch 464, Validation R²: -0.0455\n",
      "Epoch 464, Validation Loss: 0.1460\n",
      "\n",
      "Epoch 465, Training R²: 0.9244\n",
      "Epoch 465, Validation R²: 0.0703\n",
      "Epoch 465, Validation Loss: 0.1320\n",
      "\n",
      "Epoch 466, Training R²: 0.9119\n",
      "Epoch 466, Validation R²: -0.9093\n",
      "Epoch 466, Validation Loss: 0.2746\n",
      "\n",
      "Epoch 467, Training R²: 0.8257\n",
      "Epoch 467, Validation R²: -0.0216\n",
      "Epoch 467, Validation Loss: 0.1468\n",
      "\n",
      "Epoch 468, Training R²: 0.7928\n",
      "Epoch 468, Validation R²: -0.1243\n",
      "Epoch 468, Validation Loss: 0.1639\n",
      "\n",
      "Epoch 469, Training R²: 0.8207\n",
      "Epoch 469, Validation R²: -0.0164\n",
      "Epoch 469, Validation Loss: 0.1484\n",
      "\n",
      "Epoch 470, Training R²: 0.9125\n",
      "Epoch 470, Validation R²: -0.1248\n",
      "Epoch 470, Validation Loss: 0.1571\n",
      "\n",
      "Epoch 471, Training R²: 0.8848\n",
      "Epoch 471, Validation R²: 0.0186\n",
      "Epoch 471, Validation Loss: 0.1376\n",
      "\n",
      "Epoch 472, Training R²: 0.9184\n",
      "Epoch 472, Validation R²: -0.3758\n",
      "Epoch 472, Validation Loss: 0.1933\n",
      "\n",
      "Epoch 473, Training R²: 0.9195\n",
      "Epoch 473, Validation R²: 0.0448\n",
      "Epoch 473, Validation Loss: 0.1361\n",
      "\n",
      "Epoch 474, Training R²: 0.9108\n",
      "Epoch 474, Validation R²: -0.4218\n",
      "Epoch 474, Validation Loss: 0.1984\n",
      "\n",
      "Epoch 475, Training R²: 0.9178\n",
      "Epoch 475, Validation R²: -0.3539\n",
      "Epoch 475, Validation Loss: 0.1903\n",
      "\n",
      "Epoch 476, Training R²: 0.9352\n",
      "Epoch 476, Validation R²: 0.1497\n",
      "Epoch 476, Validation Loss: 0.1208\n",
      "\n",
      "Epoch 477, Training R²: 0.9377\n",
      "Epoch 477, Validation R²: -0.2634\n",
      "Epoch 477, Validation Loss: 0.1780\n",
      "\n",
      "Epoch 478, Training R²: 0.9421\n",
      "Epoch 478, Validation R²: -0.2208\n",
      "Epoch 478, Validation Loss: 0.1716\n",
      "\n",
      "Epoch 479, Training R²: 0.9136\n",
      "Epoch 479, Validation R²: -0.0650\n",
      "Epoch 479, Validation Loss: 0.1487\n",
      "\n",
      "Epoch 480, Training R²: 0.9428\n",
      "Epoch 480, Validation R²: -0.1319\n",
      "Epoch 480, Validation Loss: 0.1584\n",
      "\n",
      "Epoch 481, Training R²: 0.9348\n",
      "Epoch 481, Validation R²: -0.0764\n",
      "Epoch 481, Validation Loss: 0.1496\n",
      "\n",
      "Epoch 482, Training R²: 0.9349\n",
      "Epoch 482, Validation R²: 0.0715\n",
      "Epoch 482, Validation Loss: 0.1301\n",
      "\n",
      "Epoch 483, Training R²: 0.9102\n",
      "Epoch 483, Validation R²: -0.0406\n",
      "Epoch 483, Validation Loss: 0.1452\n",
      "\n",
      "Epoch 484, Training R²: 0.9274\n",
      "Epoch 484, Validation R²: -0.2795\n",
      "Epoch 484, Validation Loss: 0.1783\n",
      "\n",
      "Epoch 485, Training R²: 0.9292\n",
      "Epoch 485, Validation R²: -0.0413\n",
      "Epoch 485, Validation Loss: 0.1448\n",
      "\n",
      "Epoch 486, Training R²: 0.9429\n",
      "Epoch 486, Validation R²: 0.0539\n",
      "Epoch 486, Validation Loss: 0.1324\n",
      "\n",
      "Epoch 487, Training R²: 0.9382\n",
      "Epoch 487, Validation R²: -0.5179\n",
      "Epoch 487, Validation Loss: 0.2142\n",
      "\n",
      "Epoch 488, Training R²: 0.9397\n",
      "Epoch 488, Validation R²: -0.2415\n",
      "Epoch 488, Validation Loss: 0.1729\n",
      "\n",
      "Epoch 489, Training R²: 0.9412\n",
      "Epoch 489, Validation R²: 0.1130\n",
      "Epoch 489, Validation Loss: 0.1246\n",
      "\n",
      "Epoch 490, Training R²: 0.9311\n",
      "Epoch 490, Validation R²: 0.0483\n",
      "Epoch 490, Validation Loss: 0.1332\n",
      "\n",
      "Epoch 491, Training R²: 0.9420\n",
      "Epoch 491, Validation R²: -0.1931\n",
      "Epoch 491, Validation Loss: 0.1671\n",
      "\n",
      "Epoch 492, Training R²: 0.9315\n",
      "Epoch 492, Validation R²: -0.6615\n",
      "Epoch 492, Validation Loss: 0.2338\n",
      "\n",
      "Epoch 493, Training R²: 0.9213\n",
      "Epoch 493, Validation R²: 0.0100\n",
      "Epoch 493, Validation Loss: 0.1384\n",
      "\n",
      "Epoch 494, Training R²: 0.9282\n",
      "Epoch 494, Validation R²: 0.1303\n",
      "Epoch 494, Validation Loss: 0.1225\n",
      "\n",
      "Epoch 495, Training R²: 0.9036\n",
      "Epoch 495, Validation R²: 0.0007\n",
      "Epoch 495, Validation Loss: 0.1400\n",
      "\n",
      "Epoch 496, Training R²: 0.9032\n",
      "Epoch 496, Validation R²: -0.2370\n",
      "Epoch 496, Validation Loss: 0.1730\n",
      "\n",
      "Epoch 497, Training R²: 0.9427\n",
      "Epoch 497, Validation R²: -0.0507\n",
      "Epoch 497, Validation Loss: 0.1472\n",
      "\n",
      "Epoch 498, Training R²: 0.9294\n",
      "Epoch 498, Validation R²: -0.2786\n",
      "Epoch 498, Validation Loss: 0.1787\n",
      "\n",
      "Epoch 499, Training R²: 0.9405\n",
      "Epoch 499, Validation R²: -0.4452\n",
      "Epoch 499, Validation Loss: 0.2025\n",
      "\n",
      "Epoch 500, Training R²: 0.9473\n",
      "Epoch 500, Validation R²: -0.0714\n",
      "Epoch 500, Validation Loss: 0.1496\n",
      "\n",
      "Epoch 501, Training R²: 0.9557\n",
      "Epoch 501, Validation R²: -0.7972\n",
      "Epoch 501, Validation Loss: 0.2539\n",
      "\n",
      "Epoch 502, Training R²: 0.9446\n",
      "Epoch 502, Validation R²: -0.1468\n",
      "Epoch 502, Validation Loss: 0.1604\n",
      "\n",
      "Epoch 503, Training R²: 0.9561\n",
      "Epoch 503, Validation R²: 0.0139\n",
      "Epoch 503, Validation Loss: 0.1376\n",
      "\n",
      "Epoch 504, Training R²: 0.9306\n",
      "Epoch 504, Validation R²: -0.1658\n",
      "Epoch 504, Validation Loss: 0.1628\n",
      "\n",
      "Epoch 505, Training R²: 0.9265\n",
      "Epoch 505, Validation R²: -0.1425\n",
      "Epoch 505, Validation Loss: 0.1605\n",
      "\n",
      "Epoch 506, Training R²: 0.9295\n",
      "Epoch 506, Validation R²: 0.0747\n",
      "Epoch 506, Validation Loss: 0.1297\n",
      "\n",
      "Epoch 507, Training R²: 0.9216\n",
      "Epoch 507, Validation R²: 0.1240\n",
      "Epoch 507, Validation Loss: 0.1244\n",
      "\n",
      "Epoch 508, Training R²: 0.9050\n",
      "Epoch 508, Validation R²: -1.7049\n",
      "Epoch 508, Validation Loss: 0.3885\n",
      "\n",
      "Epoch 509, Training R²: 0.8958\n",
      "Epoch 509, Validation R²: -0.2554\n",
      "Epoch 509, Validation Loss: 0.1749\n",
      "\n",
      "Epoch 510, Training R²: 0.9282\n",
      "Epoch 510, Validation R²: -0.1259\n",
      "Epoch 510, Validation Loss: 0.1564\n",
      "\n",
      "Epoch 511, Training R²: 0.9363\n",
      "Epoch 511, Validation R²: 0.0309\n",
      "Epoch 511, Validation Loss: 0.1354\n",
      "\n",
      "Epoch 512, Training R²: 0.9392\n",
      "Epoch 512, Validation R²: -0.3366\n",
      "Epoch 512, Validation Loss: 0.1858\n",
      "\n",
      "Epoch 513, Training R²: 0.9482\n",
      "Epoch 513, Validation R²: -0.2950\n",
      "Epoch 513, Validation Loss: 0.1802\n",
      "\n",
      "Epoch 514, Training R²: 0.9133\n",
      "Epoch 514, Validation R²: -0.4118\n",
      "Epoch 514, Validation Loss: 0.1976\n",
      "\n",
      "Epoch 515, Training R²: 0.9401\n",
      "Epoch 515, Validation R²: 0.0342\n",
      "Epoch 515, Validation Loss: 0.1353\n",
      "\n",
      "Epoch 516, Training R²: 0.9054\n",
      "Epoch 516, Validation R²: -0.3560\n",
      "Epoch 516, Validation Loss: 0.1868\n",
      "\n",
      "Epoch 517, Training R²: 0.9072\n",
      "Epoch 517, Validation R²: -0.3539\n",
      "Epoch 517, Validation Loss: 0.1863\n",
      "\n",
      "Epoch 518, Training R²: 0.9350\n",
      "Epoch 518, Validation R²: -0.0661\n",
      "Epoch 518, Validation Loss: 0.1484\n",
      "\n",
      "Epoch 519, Training R²: 0.9208\n",
      "Epoch 519, Validation R²: -0.0456\n",
      "Epoch 519, Validation Loss: 0.1457\n",
      "\n",
      "Epoch 520, Training R²: 0.9048\n",
      "Epoch 520, Validation R²: -0.3548\n",
      "Epoch 520, Validation Loss: 0.1896\n",
      "\n",
      "Epoch 521, Training R²: 0.9295\n",
      "Epoch 521, Validation R²: -0.4329\n",
      "Epoch 521, Validation Loss: 0.1983\n",
      "\n",
      "Epoch 522, Training R²: 0.9399\n",
      "Epoch 522, Validation R²: -0.2626\n",
      "Epoch 522, Validation Loss: 0.1767\n",
      "\n",
      "Epoch 523, Training R²: 0.9349\n",
      "Epoch 523, Validation R²: -0.2197\n",
      "Epoch 523, Validation Loss: 0.1711\n",
      "\n",
      "Epoch 524, Training R²: 0.9330\n",
      "Epoch 524, Validation R²: -0.2261\n",
      "Epoch 524, Validation Loss: 0.1704\n",
      "\n",
      "Epoch 525, Training R²: 0.9250\n",
      "Epoch 525, Validation R²: -0.3671\n",
      "Epoch 525, Validation Loss: 0.1906\n",
      "\n",
      "Epoch 526, Training R²: 0.9067\n",
      "Epoch 526, Validation R²: -0.4339\n",
      "Epoch 526, Validation Loss: 0.1965\n",
      "\n",
      "Epoch 527, Training R²: 0.9163\n",
      "Epoch 527, Validation R²: -0.3232\n",
      "Epoch 527, Validation Loss: 0.1831\n",
      "\n",
      "Epoch 528, Training R²: 0.9352\n",
      "Epoch 528, Validation R²: -0.1664\n",
      "Epoch 528, Validation Loss: 0.1616\n",
      "\n",
      "Epoch 529, Training R²: 0.9371\n",
      "Epoch 529, Validation R²: -0.7140\n",
      "Epoch 529, Validation Loss: 0.2410\n",
      "\n",
      "Epoch 530, Training R²: 0.9074\n",
      "Epoch 530, Validation R²: -1.1969\n",
      "Epoch 530, Validation Loss: 0.3123\n",
      "\n",
      "Epoch 531, Training R²: 0.9012\n",
      "Epoch 531, Validation R²: -0.1861\n",
      "Epoch 531, Validation Loss: 0.1676\n",
      "\n",
      "Epoch 532, Training R²: 0.9111\n",
      "Epoch 532, Validation R²: -0.0974\n",
      "Epoch 532, Validation Loss: 0.1531\n",
      "\n",
      "Epoch 533, Training R²: 0.9246\n",
      "Epoch 533, Validation R²: -0.5821\n",
      "Epoch 533, Validation Loss: 0.2201\n",
      "\n",
      "Epoch 534, Training R²: 0.9397\n",
      "Epoch 534, Validation R²: -0.1152\n",
      "Epoch 534, Validation Loss: 0.1555\n",
      "\n",
      "Epoch 535, Training R²: 0.9408\n",
      "Epoch 535, Validation R²: -0.0521\n",
      "Epoch 535, Validation Loss: 0.1468\n",
      "\n",
      "Epoch 536, Training R²: 0.9280\n",
      "Epoch 536, Validation R²: -0.2707\n",
      "Epoch 536, Validation Loss: 0.1779\n",
      "\n",
      "Epoch 537, Training R²: 0.8614\n",
      "Epoch 537, Validation R²: -0.2150\n",
      "Epoch 537, Validation Loss: 0.1681\n",
      "\n",
      "Epoch 538, Training R²: 0.9243\n",
      "Epoch 538, Validation R²: -0.3168\n",
      "Epoch 538, Validation Loss: 0.1836\n",
      "\n",
      "Epoch 539, Training R²: 0.9164\n",
      "Epoch 539, Validation R²: -0.5746\n",
      "Epoch 539, Validation Loss: 0.2183\n",
      "\n",
      "Epoch 540, Training R²: 0.9275\n",
      "Epoch 540, Validation R²: -0.3537\n",
      "Epoch 540, Validation Loss: 0.1879\n",
      "\n",
      "Epoch 541, Training R²: 0.9308\n",
      "Epoch 541, Validation R²: 0.0808\n",
      "Epoch 541, Validation Loss: 0.1297\n",
      "\n",
      "Epoch 542, Training R²: 0.9293\n",
      "Epoch 542, Validation R²: 0.1207\n",
      "Epoch 542, Validation Loss: 0.1244\n",
      "\n",
      "Epoch 543, Training R²: 0.8727\n",
      "Epoch 543, Validation R²: -0.4664\n",
      "Epoch 543, Validation Loss: 0.2044\n",
      "\n",
      "Epoch 544, Training R²: 0.8359\n",
      "Epoch 544, Validation R²: -0.2321\n",
      "Epoch 544, Validation Loss: 0.1733\n",
      "\n",
      "Epoch 545, Training R²: 0.8221\n",
      "Epoch 545, Validation R²: 0.0917\n",
      "Epoch 545, Validation Loss: 0.1310\n",
      "\n",
      "Epoch 546, Training R²: 0.7534\n",
      "Epoch 546, Validation R²: -0.3916\n",
      "Epoch 546, Validation Loss: 0.1966\n",
      "\n",
      "Epoch 547, Training R²: 0.8752\n",
      "Epoch 547, Validation R²: -0.3717\n",
      "Epoch 547, Validation Loss: 0.1943\n",
      "\n",
      "Epoch 548, Training R²: 0.8691\n",
      "Epoch 548, Validation R²: -0.4405\n",
      "Epoch 548, Validation Loss: 0.2005\n",
      "\n",
      "Epoch 549, Training R²: 0.8732\n",
      "Epoch 549, Validation R²: -0.1017\n",
      "Epoch 549, Validation Loss: 0.1537\n",
      "\n",
      "Epoch 550, Training R²: 0.9187\n",
      "Epoch 550, Validation R²: -0.2723\n",
      "Epoch 550, Validation Loss: 0.1755\n",
      "\n",
      "Epoch 551, Training R²: 0.9219\n",
      "Epoch 551, Validation R²: -0.3823\n",
      "Epoch 551, Validation Loss: 0.1934\n",
      "\n",
      "Epoch 552, Training R²: 0.9315\n",
      "Epoch 552, Validation R²: -0.1740\n",
      "Epoch 552, Validation Loss: 0.1635\n",
      "\n",
      "Epoch 553, Training R²: 0.9148\n",
      "Epoch 553, Validation R²: -0.0368\n",
      "Epoch 553, Validation Loss: 0.1446\n",
      "\n",
      "Epoch 554, Training R²: 0.9179\n",
      "Epoch 554, Validation R²: -0.2803\n",
      "Epoch 554, Validation Loss: 0.1774\n",
      "\n",
      "Epoch 555, Training R²: 0.9294\n",
      "Epoch 555, Validation R²: -0.4149\n",
      "Epoch 555, Validation Loss: 0.1959\n",
      "\n",
      "Epoch 556, Training R²: 0.9361\n",
      "Epoch 556, Validation R²: -0.0629\n",
      "Epoch 556, Validation Loss: 0.1485\n",
      "\n",
      "Epoch 557, Training R²: 0.9275\n",
      "Epoch 557, Validation R²: -0.4934\n",
      "Epoch 557, Validation Loss: 0.2071\n",
      "\n",
      "Epoch 558, Training R²: 0.8590\n",
      "Epoch 558, Validation R²: -0.1508\n",
      "Epoch 558, Validation Loss: 0.1604\n",
      "\n",
      "Epoch 559, Training R²: 0.8041\n",
      "Epoch 559, Validation R²: -0.1596\n",
      "Epoch 559, Validation Loss: 0.1631\n",
      "\n",
      "Epoch 560, Training R²: 0.8377\n",
      "Epoch 560, Validation R²: -0.7861\n",
      "Epoch 560, Validation Loss: 0.2516\n",
      "\n",
      "Epoch 561, Training R²: 0.8719\n",
      "Epoch 561, Validation R²: -0.8651\n",
      "Epoch 561, Validation Loss: 0.2604\n",
      "\n",
      "Epoch 562, Training R²: 0.8515\n",
      "Epoch 562, Validation R²: -0.7108\n",
      "Epoch 562, Validation Loss: 0.2407\n",
      "\n",
      "Epoch 563, Training R²: 0.9119\n",
      "Epoch 563, Validation R²: -0.3687\n",
      "Epoch 563, Validation Loss: 0.1903\n",
      "\n",
      "Epoch 564, Training R²: 0.8686\n",
      "Epoch 564, Validation R²: -0.1367\n",
      "Epoch 564, Validation Loss: 0.1585\n",
      "\n",
      "Epoch 565, Training R²: 0.8999\n",
      "Epoch 565, Validation R²: 0.0981\n",
      "Epoch 565, Validation Loss: 0.1274\n",
      "\n",
      "Epoch 566, Training R²: 0.9193\n",
      "Epoch 566, Validation R²: 0.0304\n",
      "Epoch 566, Validation Loss: 0.1366\n",
      "\n",
      "Epoch 567, Training R²: 0.9119\n",
      "Epoch 567, Validation R²: -0.0391\n",
      "Epoch 567, Validation Loss: 0.1449\n",
      "\n",
      "Epoch 568, Training R²: 0.9223\n",
      "Epoch 568, Validation R²: -0.4194\n",
      "Epoch 568, Validation Loss: 0.1967\n",
      "\n",
      "Epoch 569, Training R²: 0.9169\n",
      "Epoch 569, Validation R²: -0.0718\n",
      "Epoch 569, Validation Loss: 0.1491\n",
      "\n",
      "Epoch 570, Training R²: 0.8992\n",
      "Epoch 570, Validation R²: 0.0678\n",
      "Epoch 570, Validation Loss: 0.1329\n",
      "\n",
      "Epoch 571, Training R²: 0.8952\n",
      "Epoch 571, Validation R²: -1.2894\n",
      "Epoch 571, Validation Loss: 0.3232\n",
      "\n",
      "Epoch 572, Training R²: 0.9153\n",
      "Epoch 572, Validation R²: -0.1516\n",
      "Epoch 572, Validation Loss: 0.1610\n",
      "\n",
      "Epoch 573, Training R²: 0.9150\n",
      "Epoch 573, Validation R²: -0.0303\n",
      "Epoch 573, Validation Loss: 0.1441\n",
      "\n",
      "Epoch 574, Training R²: 0.9365\n",
      "Epoch 574, Validation R²: -0.5582\n",
      "Epoch 574, Validation Loss: 0.2168\n",
      "\n",
      "Epoch 575, Training R²: 0.9307\n",
      "Epoch 575, Validation R²: -0.1028\n",
      "Epoch 575, Validation Loss: 0.1539\n",
      "\n",
      "Epoch 576, Training R²: 0.9174\n",
      "Epoch 576, Validation R²: 0.0062\n",
      "Epoch 576, Validation Loss: 0.1402\n",
      "\n",
      "Epoch 577, Training R²: 0.9099\n",
      "Epoch 577, Validation R²: -0.1544\n",
      "Epoch 577, Validation Loss: 0.1599\n",
      "\n",
      "Epoch 578, Training R²: 0.8856\n",
      "Epoch 578, Validation R²: -0.3041\n",
      "Epoch 578, Validation Loss: 0.1819\n",
      "\n",
      "Epoch 579, Training R²: 0.8849\n",
      "Epoch 579, Validation R²: -0.2474\n",
      "Epoch 579, Validation Loss: 0.1743\n",
      "\n",
      "Epoch 580, Training R²: 0.9088\n",
      "Epoch 580, Validation R²: -0.1831\n",
      "Epoch 580, Validation Loss: 0.1647\n",
      "\n",
      "Epoch 581, Training R²: 0.9064\n",
      "Epoch 581, Validation R²: -0.6596\n",
      "Epoch 581, Validation Loss: 0.2275\n",
      "\n",
      "Epoch 582, Training R²: 0.9082\n",
      "Epoch 582, Validation R²: -0.3359\n",
      "Epoch 582, Validation Loss: 0.1867\n",
      "\n",
      "Epoch 583, Training R²: 0.9059\n",
      "Epoch 583, Validation R²: -0.1011\n",
      "Epoch 583, Validation Loss: 0.1539\n",
      "\n",
      "Epoch 584, Training R²: 0.9396\n",
      "Epoch 584, Validation R²: -0.1419\n",
      "Epoch 584, Validation Loss: 0.1591\n",
      "\n",
      "Epoch 585, Training R²: 0.9291\n",
      "Epoch 585, Validation R²: -0.2007\n",
      "Epoch 585, Validation Loss: 0.1667\n",
      "\n",
      "Epoch 586, Training R²: 0.9112\n",
      "Epoch 586, Validation R²: -0.0569\n",
      "Epoch 586, Validation Loss: 0.1472\n",
      "\n",
      "Epoch 587, Training R²: 0.9104\n",
      "Epoch 587, Validation R²: 0.1187\n",
      "Epoch 587, Validation Loss: 0.1260\n",
      "\n",
      "Epoch 588, Training R²: 0.9227\n",
      "Epoch 588, Validation R²: 0.1520\n",
      "Epoch 588, Validation Loss: 0.1215\n",
      "\n",
      "Epoch 589, Training R²: 0.9000\n",
      "Epoch 589, Validation R²: -0.7629\n",
      "Epoch 589, Validation Loss: 0.2466\n",
      "\n",
      "Epoch 590, Training R²: 0.9212\n",
      "Epoch 590, Validation R²: -0.4040\n",
      "Epoch 590, Validation Loss: 0.1960\n",
      "\n",
      "Epoch 591, Training R²: 0.9314\n",
      "Epoch 591, Validation R²: 0.0268\n",
      "Epoch 591, Validation Loss: 0.1369\n",
      "\n",
      "Epoch 592, Training R²: 0.9215\n",
      "Epoch 592, Validation R²: -0.5002\n",
      "Epoch 592, Validation Loss: 0.2104\n",
      "\n",
      "Epoch 593, Training R²: 0.9225\n",
      "Epoch 593, Validation R²: 0.0326\n",
      "Epoch 593, Validation Loss: 0.1379\n",
      "\n",
      "Epoch 594, Training R²: 0.9084\n",
      "Epoch 594, Validation R²: -0.1685\n",
      "Epoch 594, Validation Loss: 0.1623\n",
      "\n",
      "Epoch 595, Training R²: 0.9000\n",
      "Epoch 595, Validation R²: 0.0138\n",
      "Epoch 595, Validation Loss: 0.1385\n",
      "\n",
      "Epoch 596, Training R²: 0.9388\n",
      "Epoch 596, Validation R²: -0.2417\n",
      "Epoch 596, Validation Loss: 0.1730\n",
      "\n",
      "Epoch 597, Training R²: 0.9352\n",
      "Epoch 597, Validation R²: -0.1668\n",
      "Epoch 597, Validation Loss: 0.1620\n",
      "\n",
      "Epoch 598, Training R²: 0.9413\n",
      "Epoch 598, Validation R²: -0.2385\n",
      "Epoch 598, Validation Loss: 0.1720\n",
      "\n",
      "Epoch 599, Training R²: 0.9350\n",
      "Epoch 599, Validation R²: -0.0527\n",
      "Epoch 599, Validation Loss: 0.1483\n",
      "\n",
      "Epoch 600, Training R²: 0.9322\n",
      "Epoch 600, Validation R²: -0.1631\n",
      "Epoch 600, Validation Loss: 0.1620\n",
      "\n",
      "Epoch 601, Training R²: 0.9155\n",
      "Epoch 601, Validation R²: 0.1001\n",
      "Epoch 601, Validation Loss: 0.1269\n",
      "\n",
      "Epoch 602, Training R²: 0.9110\n",
      "Epoch 602, Validation R²: 0.0532\n",
      "Epoch 602, Validation Loss: 0.1339\n",
      "\n",
      "Epoch 603, Training R²: 0.9267\n",
      "Epoch 603, Validation R²: 0.0740\n",
      "Epoch 603, Validation Loss: 0.1301\n",
      "\n",
      "Epoch 604, Training R²: 0.9283\n",
      "Epoch 604, Validation R²: -0.1063\n",
      "Epoch 604, Validation Loss: 0.1540\n",
      "\n",
      "Epoch 605, Training R²: 0.9309\n",
      "Epoch 605, Validation R²: -0.0763\n",
      "Epoch 605, Validation Loss: 0.1502\n",
      "\n",
      "Epoch 606, Training R²: 0.9345\n",
      "Epoch 606, Validation R²: -0.0741\n",
      "Epoch 606, Validation Loss: 0.1497\n",
      "\n",
      "Epoch 607, Training R²: 0.9160\n",
      "Epoch 607, Validation R²: -0.0698\n",
      "Epoch 607, Validation Loss: 0.1491\n",
      "\n",
      "Epoch 608, Training R²: 0.8895\n",
      "Epoch 608, Validation R²: -0.7322\n",
      "Epoch 608, Validation Loss: 0.2416\n",
      "\n",
      "Epoch 609, Training R²: 0.9205\n",
      "Epoch 609, Validation R²: -0.1699\n",
      "Epoch 609, Validation Loss: 0.1623\n",
      "\n",
      "Epoch 610, Training R²: 0.9255\n",
      "Epoch 610, Validation R²: 0.1164\n",
      "Epoch 610, Validation Loss: 0.1249\n",
      "\n",
      "Epoch 611, Training R²: 0.9164\n",
      "Epoch 611, Validation R²: 0.0314\n",
      "Epoch 611, Validation Loss: 0.1361\n",
      "\n",
      "Epoch 612, Training R²: 0.9334\n",
      "Epoch 612, Validation R²: -0.2587\n",
      "Epoch 612, Validation Loss: 0.1748\n",
      "\n",
      "Epoch 613, Training R²: 0.9358\n",
      "Epoch 613, Validation R²: 0.0084\n",
      "Epoch 613, Validation Loss: 0.1395\n",
      "\n",
      "Epoch 614, Training R²: 0.9438\n",
      "Epoch 614, Validation R²: -0.2357\n",
      "Epoch 614, Validation Loss: 0.1720\n",
      "\n",
      "Epoch 615, Training R²: 0.9360\n",
      "Epoch 615, Validation R²: -0.4610\n",
      "Epoch 615, Validation Loss: 0.2016\n",
      "\n",
      "Epoch 616, Training R²: 0.9326\n",
      "Epoch 616, Validation R²: 0.0881\n",
      "Epoch 616, Validation Loss: 0.1293\n",
      "\n",
      "Epoch 617, Training R²: 0.9216\n",
      "Epoch 617, Validation R²: -0.0428\n",
      "Epoch 617, Validation Loss: 0.1457\n",
      "\n",
      "Epoch 618, Training R²: 0.9293\n",
      "Epoch 618, Validation R²: -1.2212\n",
      "Epoch 618, Validation Loss: 0.3115\n",
      "\n",
      "Epoch 619, Training R²: 0.8904\n",
      "Epoch 619, Validation R²: 0.0403\n",
      "Epoch 619, Validation Loss: 0.1355\n",
      "\n",
      "Epoch 620, Training R²: 0.9154\n",
      "Epoch 620, Validation R²: 0.1111\n",
      "Epoch 620, Validation Loss: 0.1283\n",
      "\n",
      "Epoch 621, Training R²: 0.9009\n",
      "Epoch 621, Validation R²: -0.4680\n",
      "Epoch 621, Validation Loss: 0.2049\n",
      "\n",
      "Epoch 622, Training R²: 0.9130\n",
      "Epoch 622, Validation R²: -0.3119\n",
      "Epoch 622, Validation Loss: 0.1828\n",
      "\n",
      "Epoch 623, Training R²: 0.9002\n",
      "Epoch 623, Validation R²: 0.0038\n",
      "Epoch 623, Validation Loss: 0.1398\n",
      "\n",
      "Epoch 624, Training R²: 0.8986\n",
      "Epoch 624, Validation R²: -0.0126\n",
      "Epoch 624, Validation Loss: 0.1430\n",
      "\n",
      "Epoch 625, Training R²: 0.8262\n",
      "Epoch 625, Validation R²: -0.0563\n",
      "Epoch 625, Validation Loss: 0.1516\n",
      "\n",
      "Epoch 626, Training R²: 0.9243\n",
      "Epoch 626, Validation R²: -0.0263\n",
      "Epoch 626, Validation Loss: 0.1443\n",
      "\n",
      "Epoch 627, Training R²: 0.9348\n",
      "Epoch 627, Validation R²: 0.1353\n",
      "Epoch 627, Validation Loss: 0.1224\n",
      "\n",
      "Epoch 628, Training R²: 0.9304\n",
      "Epoch 628, Validation R²: -0.2459\n",
      "Epoch 628, Validation Loss: 0.1734\n",
      "\n",
      "Epoch 629, Training R²: 0.9197\n",
      "Epoch 629, Validation R²: -0.2131\n",
      "Epoch 629, Validation Loss: 0.1694\n",
      "\n",
      "Epoch 630, Training R²: 0.8977\n",
      "Epoch 630, Validation R²: 0.0952\n",
      "Epoch 630, Validation Loss: 0.1308\n",
      "\n",
      "Epoch 631, Training R²: 0.9116\n",
      "Epoch 631, Validation R²: -0.1768\n",
      "Epoch 631, Validation Loss: 0.1647\n",
      "\n",
      "Epoch 632, Training R²: 0.9198\n",
      "Epoch 632, Validation R²: -0.1762\n",
      "Epoch 632, Validation Loss: 0.1633\n",
      "\n",
      "Epoch 633, Training R²: 0.9041\n",
      "Epoch 633, Validation R²: -0.0403\n",
      "Epoch 633, Validation Loss: 0.1458\n",
      "\n",
      "Epoch 634, Training R²: 0.9269\n",
      "Epoch 634, Validation R²: -0.1979\n",
      "Epoch 634, Validation Loss: 0.1668\n",
      "\n",
      "Epoch 635, Training R²: 0.9136\n",
      "Epoch 635, Validation R²: -0.0867\n",
      "Epoch 635, Validation Loss: 0.1514\n",
      "\n",
      "Epoch 636, Training R²: 0.9295\n",
      "Epoch 636, Validation R²: -0.0363\n",
      "Epoch 636, Validation Loss: 0.1447\n",
      "\n",
      "Epoch 637, Training R²: 0.9198\n",
      "Epoch 637, Validation R²: -0.1849\n",
      "Epoch 637, Validation Loss: 0.1658\n",
      "\n",
      "Epoch 638, Training R²: 0.9073\n",
      "Epoch 638, Validation R²: 0.0374\n",
      "Epoch 638, Validation Loss: 0.1354\n",
      "\n",
      "Epoch 639, Training R²: 0.9355\n",
      "Epoch 639, Validation R²: 0.0439\n",
      "Epoch 639, Validation Loss: 0.1341\n",
      "\n",
      "Epoch 640, Training R²: 0.9333\n",
      "Epoch 640, Validation R²: -0.3836\n",
      "Epoch 640, Validation Loss: 0.1926\n",
      "\n",
      "Epoch 641, Training R²: 0.9176\n",
      "Epoch 641, Validation R²: -0.2850\n",
      "Epoch 641, Validation Loss: 0.1793\n",
      "\n",
      "Epoch 642, Training R²: 0.9276\n",
      "Epoch 642, Validation R²: -0.0176\n",
      "Epoch 642, Validation Loss: 0.1452\n",
      "\n",
      "Epoch 643, Training R²: 0.9354\n",
      "Epoch 643, Validation R²: -0.5197\n",
      "Epoch 643, Validation Loss: 0.2127\n",
      "\n",
      "Epoch 644, Training R²: 0.9134\n",
      "Epoch 644, Validation R²: -0.4990\n",
      "Epoch 644, Validation Loss: 0.2077\n",
      "\n",
      "Epoch 645, Training R²: 0.8870\n",
      "Epoch 645, Validation R²: -0.2520\n",
      "Epoch 645, Validation Loss: 0.1742\n",
      "\n",
      "Epoch 646, Training R²: 0.8776\n",
      "Epoch 646, Validation R²: -0.0234\n",
      "Epoch 646, Validation Loss: 0.1449\n",
      "\n",
      "Epoch 647, Training R²: 0.9215\n",
      "Epoch 647, Validation R²: 0.1318\n",
      "Epoch 647, Validation Loss: 0.1253\n",
      "\n",
      "Epoch 648, Training R²: 0.9067\n",
      "Epoch 648, Validation R²: -0.0882\n",
      "Epoch 648, Validation Loss: 0.1520\n",
      "\n",
      "Epoch 649, Training R²: 0.9069\n",
      "Epoch 649, Validation R²: -0.2602\n",
      "Epoch 649, Validation Loss: 0.1745\n",
      "\n",
      "Epoch 650, Training R²: 0.9377\n",
      "Epoch 650, Validation R²: -0.0218\n",
      "Epoch 650, Validation Loss: 0.1431\n",
      "\n",
      "Epoch 651, Training R²: 0.9279\n",
      "Epoch 651, Validation R²: -0.0769\n",
      "Epoch 651, Validation Loss: 0.1506\n",
      "\n",
      "Epoch 652, Training R²: 0.9125\n",
      "Epoch 652, Validation R²: 0.0808\n",
      "Epoch 652, Validation Loss: 0.1312\n",
      "\n",
      "Epoch 653, Training R²: 0.9123\n",
      "Epoch 653, Validation R²: -0.5850\n",
      "Epoch 653, Validation Loss: 0.2236\n",
      "\n",
      "Epoch 654, Training R²: 0.9066\n",
      "Epoch 654, Validation R²: -0.7620\n",
      "Epoch 654, Validation Loss: 0.2437\n",
      "\n",
      "Epoch 655, Training R²: 0.9115\n",
      "Epoch 655, Validation R²: -0.3786\n",
      "Epoch 655, Validation Loss: 0.1943\n",
      "\n",
      "Epoch 656, Training R²: 0.9261\n",
      "Epoch 656, Validation R²: -0.5789\n",
      "Epoch 656, Validation Loss: 0.2169\n",
      "\n",
      "Epoch 657, Training R²: 0.9262\n",
      "Epoch 657, Validation R²: -0.3080\n",
      "Epoch 657, Validation Loss: 0.1820\n",
      "\n",
      "Epoch 658, Training R²: 0.9359\n",
      "Epoch 658, Validation R²: 0.0759\n",
      "Epoch 658, Validation Loss: 0.1306\n",
      "\n",
      "Epoch 659, Training R²: 0.9151\n",
      "Epoch 659, Validation R²: 0.0264\n",
      "Epoch 659, Validation Loss: 0.1363\n",
      "\n",
      "Epoch 660, Training R²: 0.9041\n",
      "Epoch 660, Validation R²: -0.4317\n",
      "Epoch 660, Validation Loss: 0.1995\n",
      "\n",
      "Epoch 661, Training R²: 0.8872\n",
      "Epoch 661, Validation R²: -2.4990\n",
      "Epoch 661, Validation Loss: 0.4819\n",
      "\n",
      "Epoch 662, Training R²: 0.7996\n",
      "Epoch 662, Validation R²: -0.0155\n",
      "Epoch 662, Validation Loss: 0.1430\n",
      "\n",
      "Epoch 663, Training R²: 0.9160\n",
      "Epoch 663, Validation R²: 0.1308\n",
      "Epoch 663, Validation Loss: 0.1254\n",
      "\n",
      "Epoch 664, Training R²: 0.9195\n",
      "Epoch 664, Validation R²: -0.0429\n",
      "Epoch 664, Validation Loss: 0.1464\n",
      "\n",
      "Epoch 665, Training R²: 0.9108\n",
      "Epoch 665, Validation R²: -1.1951\n",
      "Epoch 665, Validation Loss: 0.3087\n",
      "\n",
      "Epoch 666, Training R²: 0.9123\n",
      "Epoch 666, Validation R²: 0.0326\n",
      "Epoch 666, Validation Loss: 0.1362\n",
      "\n",
      "Epoch 667, Training R²: 0.8838\n",
      "Epoch 667, Validation R²: -0.0415\n",
      "Epoch 667, Validation Loss: 0.1455\n",
      "\n",
      "Epoch 668, Training R²: 0.9184\n",
      "Epoch 668, Validation R²: -0.1806\n",
      "Epoch 668, Validation Loss: 0.1654\n",
      "\n",
      "Epoch 669, Training R²: 0.9086\n",
      "Epoch 669, Validation R²: -0.4301\n",
      "Epoch 669, Validation Loss: 0.2018\n",
      "\n",
      "Epoch 670, Training R²: 0.9032\n",
      "Epoch 670, Validation R²: -0.6411\n",
      "Epoch 670, Validation Loss: 0.2286\n",
      "\n",
      "Epoch 671, Training R²: 0.9180\n",
      "Epoch 671, Validation R²: -0.0239\n",
      "Epoch 671, Validation Loss: 0.1429\n",
      "\n",
      "Epoch 672, Training R²: 0.9354\n",
      "Epoch 672, Validation R²: -0.2878\n",
      "Epoch 672, Validation Loss: 0.1786\n",
      "\n",
      "Epoch 673, Training R²: 0.9367\n",
      "Epoch 673, Validation R²: -0.1701\n",
      "Epoch 673, Validation Loss: 0.1631\n",
      "\n",
      "Epoch 674, Training R²: 0.9306\n",
      "Epoch 674, Validation R²: -0.3882\n",
      "Epoch 674, Validation Loss: 0.1923\n",
      "\n",
      "Epoch 675, Training R²: 0.9357\n",
      "Epoch 675, Validation R²: 0.1396\n",
      "Epoch 675, Validation Loss: 0.1221\n",
      "\n",
      "Epoch 676, Training R²: 0.9280\n",
      "Epoch 676, Validation R²: -0.0931\n",
      "Epoch 676, Validation Loss: 0.1531\n",
      "\n",
      "Epoch 677, Training R²: 0.9281\n",
      "Epoch 677, Validation R²: -0.3860\n",
      "Epoch 677, Validation Loss: 0.1933\n",
      "\n",
      "Epoch 678, Training R²: 0.9307\n",
      "Epoch 678, Validation R²: 0.1213\n",
      "Epoch 678, Validation Loss: 0.1259\n",
      "\n",
      "Epoch 679, Training R²: 0.9194\n",
      "Epoch 679, Validation R²: -0.7012\n",
      "Epoch 679, Validation Loss: 0.2379\n",
      "\n",
      "Epoch 680, Training R²: 0.9213\n",
      "Epoch 680, Validation R²: -0.1355\n",
      "Epoch 680, Validation Loss: 0.1600\n",
      "\n",
      "Epoch 681, Training R²: 0.9381\n",
      "Epoch 681, Validation R²: 0.0522\n",
      "Epoch 681, Validation Loss: 0.1331\n",
      "\n",
      "Epoch 682, Training R²: 0.9253\n",
      "Epoch 682, Validation R²: -0.0043\n",
      "Epoch 682, Validation Loss: 0.1422\n",
      "\n",
      "Epoch 683, Training R²: 0.9268\n",
      "Epoch 683, Validation R²: -0.1143\n",
      "Epoch 683, Validation Loss: 0.1555\n",
      "\n",
      "Epoch 684, Training R²: 0.9361\n",
      "Epoch 684, Validation R²: -0.0663\n",
      "Epoch 684, Validation Loss: 0.1487\n",
      "\n",
      "Epoch 685, Training R²: 0.9094\n",
      "Epoch 685, Validation R²: -0.3262\n",
      "Epoch 685, Validation Loss: 0.1840\n",
      "\n",
      "Epoch 686, Training R²: 0.8950\n",
      "Epoch 686, Validation R²: -0.0481\n",
      "Epoch 686, Validation Loss: 0.1464\n",
      "\n",
      "Epoch 687, Training R²: 0.8955\n",
      "Epoch 687, Validation R²: -0.7199\n",
      "Epoch 687, Validation Loss: 0.2395\n",
      "\n",
      "Epoch 688, Training R²: 0.9193\n",
      "Epoch 688, Validation R²: 0.0223\n",
      "Epoch 688, Validation Loss: 0.1396\n",
      "\n",
      "Epoch 689, Training R²: 0.9091\n",
      "Epoch 689, Validation R²: -0.5735\n",
      "Epoch 689, Validation Loss: 0.2199\n",
      "\n",
      "Epoch 690, Training R²: 0.8419\n",
      "Epoch 690, Validation R²: 0.0244\n",
      "Epoch 690, Validation Loss: 0.1406\n",
      "\n",
      "Epoch 691, Training R²: 0.8494\n",
      "Epoch 691, Validation R²: -1.1105\n",
      "Epoch 691, Validation Loss: 0.2942\n",
      "\n",
      "Epoch 692, Training R²: 0.8966\n",
      "Epoch 692, Validation R²: 0.1607\n",
      "Epoch 692, Validation Loss: 0.1211\n",
      "\n",
      "Epoch 693, Training R²: 0.9201\n",
      "Epoch 693, Validation R²: -0.0155\n",
      "Epoch 693, Validation Loss: 0.1436\n",
      "\n",
      "Epoch 694, Training R²: 0.9200\n",
      "Epoch 694, Validation R²: -0.5789\n",
      "Epoch 694, Validation Loss: 0.2219\n",
      "\n",
      "Epoch 695, Training R²: 0.8993\n",
      "Epoch 695, Validation R²: -0.0210\n",
      "Epoch 695, Validation Loss: 0.1449\n",
      "\n",
      "Epoch 696, Training R²: 0.9086\n",
      "Epoch 696, Validation R²: 0.0292\n",
      "Epoch 696, Validation Loss: 0.1361\n",
      "\n",
      "Epoch 697, Training R²: 0.9386\n",
      "Epoch 697, Validation R²: -0.0521\n",
      "Epoch 697, Validation Loss: 0.1493\n",
      "\n",
      "Epoch 698, Training R²: 0.9356\n",
      "Epoch 698, Validation R²: -0.2764\n",
      "Epoch 698, Validation Loss: 0.1774\n",
      "\n",
      "Epoch 699, Training R²: 0.9424\n",
      "Epoch 699, Validation R²: -0.1203\n",
      "Epoch 699, Validation Loss: 0.1566\n",
      "\n",
      "Epoch 700, Training R²: 0.9376\n",
      "Epoch 700, Validation R²: 0.0260\n",
      "Epoch 700, Validation Loss: 0.1364\n",
      "\n",
      "Epoch 701, Training R²: 0.9432\n",
      "Epoch 701, Validation R²: 0.0477\n",
      "Epoch 701, Validation Loss: 0.1342\n",
      "\n",
      "Epoch 702, Training R²: 0.9390\n",
      "Epoch 702, Validation R²: -0.1517\n",
      "Epoch 702, Validation Loss: 0.1601\n",
      "\n",
      "Epoch 703, Training R²: 0.9252\n",
      "Epoch 703, Validation R²: -0.3255\n",
      "Epoch 703, Validation Loss: 0.1842\n",
      "\n",
      "Epoch 704, Training R²: 0.9093\n",
      "Epoch 704, Validation R²: -0.0450\n",
      "Epoch 704, Validation Loss: 0.1465\n",
      "\n",
      "Epoch 705, Training R²: 0.8956\n",
      "Epoch 705, Validation R²: -0.8282\n",
      "Epoch 705, Validation Loss: 0.2535\n",
      "\n",
      "Epoch 706, Training R²: 0.8815\n",
      "Epoch 706, Validation R²: 0.0333\n",
      "Epoch 706, Validation Loss: 0.1368\n",
      "\n",
      "Epoch 707, Training R²: 0.9173\n",
      "Epoch 707, Validation R²: -0.3839\n",
      "Epoch 707, Validation Loss: 0.1917\n",
      "\n",
      "Epoch 708, Training R²: 0.9034\n",
      "Epoch 708, Validation R²: -0.0393\n",
      "Epoch 708, Validation Loss: 0.1451\n",
      "\n",
      "Epoch 709, Training R²: 0.8960\n",
      "Epoch 709, Validation R²: 0.0529\n",
      "Epoch 709, Validation Loss: 0.1369\n",
      "\n",
      "Epoch 710, Training R²: 0.8801\n",
      "Epoch 710, Validation R²: -0.2398\n",
      "Epoch 710, Validation Loss: 0.1734\n",
      "\n",
      "Epoch 711, Training R²: 0.9074\n",
      "Epoch 711, Validation R²: -0.2933\n",
      "Epoch 711, Validation Loss: 0.1795\n",
      "\n",
      "Epoch 712, Training R²: 0.9091\n",
      "Epoch 712, Validation R²: -0.7805\n",
      "Epoch 712, Validation Loss: 0.2507\n",
      "\n",
      "Epoch 713, Training R²: 0.9096\n",
      "Epoch 713, Validation R²: -0.2807\n",
      "Epoch 713, Validation Loss: 0.1821\n",
      "\n",
      "Epoch 714, Training R²: 0.9221\n",
      "Epoch 714, Validation R²: -0.1492\n",
      "Epoch 714, Validation Loss: 0.1599\n",
      "\n",
      "Epoch 715, Training R²: 0.9362\n",
      "Epoch 715, Validation R²: -0.4066\n",
      "Epoch 715, Validation Loss: 0.1952\n",
      "\n",
      "Epoch 716, Training R²: 0.9233\n",
      "Epoch 716, Validation R²: -0.2040\n",
      "Epoch 716, Validation Loss: 0.1674\n",
      "\n",
      "Epoch 717, Training R²: 0.9110\n",
      "Epoch 717, Validation R²: 0.0933\n",
      "Epoch 717, Validation Loss: 0.1295\n",
      "\n",
      "Epoch 718, Training R²: 0.9234\n",
      "Epoch 718, Validation R²: -0.0081\n",
      "Epoch 718, Validation Loss: 0.1422\n",
      "\n",
      "Epoch 719, Training R²: 0.9265\n",
      "Epoch 719, Validation R²: -0.5020\n",
      "Epoch 719, Validation Loss: 0.2089\n",
      "\n",
      "Epoch 720, Training R²: 0.9322\n",
      "Epoch 720, Validation R²: -0.1500\n",
      "Epoch 720, Validation Loss: 0.1598\n",
      "\n",
      "Epoch 721, Training R²: 0.9280\n",
      "Epoch 721, Validation R²: -0.0371\n",
      "Epoch 721, Validation Loss: 0.1457\n",
      "\n",
      "Epoch 722, Training R²: 0.9365\n",
      "Epoch 722, Validation R²: -0.0902\n",
      "Epoch 722, Validation Loss: 0.1516\n",
      "\n",
      "Epoch 723, Training R²: 0.9384\n",
      "Epoch 723, Validation R²: -0.0856\n",
      "Epoch 723, Validation Loss: 0.1511\n",
      "\n",
      "Epoch 724, Training R²: 0.9433\n",
      "Epoch 724, Validation R²: -0.4111\n",
      "Epoch 724, Validation Loss: 0.1957\n",
      "\n",
      "Epoch 725, Training R²: 0.9314\n",
      "Epoch 725, Validation R²: -0.0834\n",
      "Epoch 725, Validation Loss: 0.1512\n",
      "\n",
      "Epoch 726, Training R²: 0.9309\n",
      "Epoch 726, Validation R²: 0.0861\n",
      "Epoch 726, Validation Loss: 0.1298\n",
      "\n",
      "Epoch 727, Training R²: 0.9340\n",
      "Epoch 727, Validation R²: 0.0725\n",
      "Epoch 727, Validation Loss: 0.1314\n",
      "\n",
      "Epoch 728, Training R²: 0.9315\n",
      "Epoch 728, Validation R²: -0.0634\n",
      "Epoch 728, Validation Loss: 0.1482\n",
      "\n",
      "Epoch 729, Training R²: 0.9202\n",
      "Epoch 729, Validation R²: -0.3665\n",
      "Epoch 729, Validation Loss: 0.1896\n",
      "\n",
      "Epoch 730, Training R²: 0.9327\n",
      "Epoch 730, Validation R²: 0.0470\n",
      "Epoch 730, Validation Loss: 0.1340\n",
      "\n",
      "Epoch 731, Training R²: 0.9249\n",
      "Epoch 731, Validation R²: -1.0553\n",
      "Epoch 731, Validation Loss: 0.2856\n",
      "\n",
      "Epoch 732, Training R²: 0.9344\n",
      "Epoch 732, Validation R²: -0.0787\n",
      "Epoch 732, Validation Loss: 0.1504\n",
      "\n",
      "Epoch 733, Training R²: 0.9083\n",
      "Epoch 733, Validation R²: -0.0468\n",
      "Epoch 733, Validation Loss: 0.1464\n",
      "\n",
      "Epoch 734, Training R²: 0.9215\n",
      "Epoch 734, Validation R²: 0.0287\n",
      "Epoch 734, Validation Loss: 0.1369\n",
      "\n",
      "Epoch 735, Training R²: 0.9007\n",
      "Epoch 735, Validation R²: -0.0384\n",
      "Epoch 735, Validation Loss: 0.1450\n",
      "\n",
      "Epoch 736, Training R²: 0.9241\n",
      "Epoch 736, Validation R²: 0.0766\n",
      "Epoch 736, Validation Loss: 0.1323\n",
      "\n",
      "Epoch 737, Training R²: 0.9052\n",
      "Epoch 737, Validation R²: -0.9130\n",
      "Epoch 737, Validation Loss: 0.2664\n",
      "\n",
      "Epoch 738, Training R²: 0.8769\n",
      "Epoch 738, Validation R²: -0.5860\n",
      "Epoch 738, Validation Loss: 0.2210\n",
      "\n",
      "Epoch 739, Training R²: 0.9161\n",
      "Epoch 739, Validation R²: -0.0974\n",
      "Epoch 739, Validation Loss: 0.1528\n",
      "\n",
      "Epoch 740, Training R²: 0.9364\n",
      "Epoch 740, Validation R²: -0.1213\n",
      "Epoch 740, Validation Loss: 0.1559\n",
      "\n",
      "Epoch 741, Training R²: 0.9477\n",
      "Epoch 741, Validation R²: -0.2268\n",
      "Epoch 741, Validation Loss: 0.1715\n",
      "\n",
      "Epoch 742, Training R²: 0.9350\n",
      "Epoch 742, Validation R²: -0.2787\n",
      "Epoch 742, Validation Loss: 0.1771\n",
      "\n",
      "Epoch 743, Training R²: 0.9291\n",
      "Epoch 743, Validation R²: 0.0353\n",
      "Epoch 743, Validation Loss: 0.1365\n",
      "\n",
      "Epoch 744, Training R²: 0.9223\n",
      "Epoch 744, Validation R²: -0.0267\n",
      "Epoch 744, Validation Loss: 0.1437\n",
      "\n",
      "Epoch 745, Training R²: 0.9381\n",
      "Epoch 745, Validation R²: -0.0846\n",
      "Epoch 745, Validation Loss: 0.1518\n",
      "\n",
      "Epoch 746, Training R²: 0.9308\n",
      "Epoch 746, Validation R²: -0.1387\n",
      "Epoch 746, Validation Loss: 0.1584\n",
      "\n",
      "Epoch 747, Training R²: 0.9189\n",
      "Epoch 747, Validation R²: -0.4582\n",
      "Epoch 747, Validation Loss: 0.2041\n",
      "\n",
      "Epoch 748, Training R²: 0.9061\n",
      "Epoch 748, Validation R²: -0.0796\n",
      "Epoch 748, Validation Loss: 0.1502\n",
      "\n",
      "Epoch 749, Training R²: 0.8898\n",
      "Epoch 749, Validation R²: -0.9032\n",
      "Epoch 749, Validation Loss: 0.2645\n",
      "\n",
      "Epoch 750, Training R²: 0.8880\n",
      "Epoch 750, Validation R²: -0.1100\n",
      "Epoch 750, Validation Loss: 0.1547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store R² values for each epoch\n",
    "train_r2_scores = []\n",
    "val_r2_scores = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "\n",
    "    for combined_input, measurement_features, targets in train_loader:\n",
    "        combined_input = combined_input.cuda()\n",
    "        measurement_features = measurement_features.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(combined_input, measurement_features)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store true and predicted values for R² calculation\n",
    "        y_train_true.extend(targets.cpu().numpy().flatten())\n",
    "        y_train_pred.extend(outputs.cpu().detach().numpy().flatten())\n",
    "\n",
    "    # Calculate R² for the training set after the epoch\n",
    "    train_r2 = r2_score(y_train_true, y_train_pred)\n",
    "    train_r2_scores.append(train_r2)\n",
    "    print(f'Epoch {epoch+1}, Training R²: {train_r2:.4f}')\n",
    "\n",
    "    # Normalize train loss by number of batches\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    y_val_true = []\n",
    "    y_val_pred = []\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for combined_input, measurement_features, targets in val_loader:\n",
    "            combined_input = combined_input.cuda()\n",
    "            measurement_features = measurement_features.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(combined_input, measurement_features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Store true and predicted values for R² calculation\n",
    "            y_val_true.extend(targets.cpu().numpy().flatten())\n",
    "            y_val_pred.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "        # Calculate R² for the validation set after the epoch\n",
    "        val_r2 = r2_score(y_val_true, y_val_pred)\n",
    "        val_r2_scores.append(val_r2)\n",
    "        print(f'Epoch {epoch+1}, Validation R²: {val_r2:.4f}')\n",
    "\n",
    "        val_loss /= len(val_loader)  # Normalize val loss by number of batches\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "\n",
    "#     train_loss = 0\n",
    "\n",
    "#     for combined_input, measurement_features, targets in train_loader:\n",
    "#         combined_input = combined_input.cuda()\n",
    "#         measurement_features = measurement_features.cuda()\n",
    "#         targets = targets.cuda()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(combined_input, measurement_features)\n",
    "\n",
    "#         # Compute loss and backpropagate\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         train_loss += loss.item()\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     train_losses.append(train_loss)\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_loss = 0\n",
    "#         for combined_input, measurement_features, targets in val_loader:\n",
    "#             combined_input = combined_input.cuda()\n",
    "#             measurement_features = measurement_features.cuda()\n",
    "#             targets = targets.cuda()\n",
    "\n",
    "#             # Forward pass\n",
    "#             outputs = model(combined_input, measurement_features)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#         val_loss /= len(val_loader)\n",
    "#         val_losses.append(val_loss)\n",
    "#         print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have lists storing loss values per epoch\n",
    "epochs = range(2, num_epochs + 1)\n",
    "plt.plot(epochs, train_losses[1:], label='Training Loss')\n",
    "plt.plot(epochs, val_losses[1:], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for combined_input, measurement_features, target in test_loader:\n",
    "        combined_input = combined_input.cuda()\n",
    "        measurement_features = measurement_features.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(combined_input, measurement_features)\n",
    "        predictions.extend(outputs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(0.81568),\n",
       " np.float32(0.66678643),\n",
       " np.float32(0.44736522),\n",
       " np.float32(4.9514146),\n",
       " np.float32(1.0596786),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.43775642),\n",
       " np.float32(3.400614),\n",
       " np.float32(1.8555684),\n",
       " np.float32(2.1269488),\n",
       " np.float32(0.48700997),\n",
       " np.float32(0.59771514),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.7556182),\n",
       " np.float32(0.43775642),\n",
       " np.float32(1.3025647),\n",
       " np.float32(0.47428557),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.43775642),\n",
       " np.float32(2.6866634),\n",
       " np.float32(0.45697966),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.5352905),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.44918844),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.50414276),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.43775642),\n",
       " np.float32(0.43775642)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.read_csv('./data_full/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.concat([preds_df['Pothole number'], pd.Series(predictions, name='Bags used')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pothole number</th>\n",
       "      <th>Bags used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>0.815680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>0.666786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0.447365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>4.951415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>1.059679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>406</td>\n",
       "      <td>3.400614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>434</td>\n",
       "      <td>1.855568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>450</td>\n",
       "      <td>2.126949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>470</td>\n",
       "      <td>0.487010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>473</td>\n",
       "      <td>0.597715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>479</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1040</td>\n",
       "      <td>0.755618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1086</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1115</td>\n",
       "      <td>1.302565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>0.474286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1161</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1162</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1181</td>\n",
       "      <td>2.686663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1198</td>\n",
       "      <td>0.456980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1205</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.535290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1270</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1278</td>\n",
       "      <td>0.449188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1280</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1296</td>\n",
       "      <td>0.504143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1409</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1430</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1438</td>\n",
       "      <td>0.437756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pothole number  Bags used\n",
       "0              103   0.815680\n",
       "1              104   0.666786\n",
       "2              105   0.447365\n",
       "3              108   4.951415\n",
       "4              114   1.059679\n",
       "5              143   0.437756\n",
       "6              144   0.437756\n",
       "7              406   3.400614\n",
       "8              434   1.855568\n",
       "9              450   2.126949\n",
       "10             470   0.487010\n",
       "11             473   0.597715\n",
       "12             479   0.437756\n",
       "13            1040   0.755618\n",
       "14            1086   0.437756\n",
       "15            1115   1.302565\n",
       "16            1134   0.474286\n",
       "17            1161   0.437756\n",
       "18            1162   0.437756\n",
       "19            1181   2.686663\n",
       "20            1198   0.456980\n",
       "21            1205   0.437756\n",
       "22            1250   0.535290\n",
       "23            1270   0.437756\n",
       "24            1278   0.449188\n",
       "25            1280   0.437756\n",
       "26            1296   0.504143\n",
       "27            1409   0.437756\n",
       "28            1430   0.437756\n",
       "29            1438   0.437756"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_csv('cnn4_preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
