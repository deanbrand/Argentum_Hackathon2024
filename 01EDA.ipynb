{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will take a closer look at the pothole data that we are dealing with. On first glance, the data is very chaotic and fairly low quality, so it can use some work neatening up before we start building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV file\n",
    "train_labels = pd.read_csv('./data_full/train_labels_big.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pothole number</th>\n",
       "      <th>Bags used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pothole number  Bags used \n",
       "0             101         0.5\n",
       "1             102         1.0\n",
       "2             106         0.5\n",
       "3             107         0.5\n",
       "4             109         0.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: List all images and annotations\n",
    "image_folder = './data_full/train_images'\n",
    "annotation_folder = './data_full/train_annotations'\n",
    "\n",
    "# Get list of image files (without extensions)\n",
    "image_files = set([os.path.splitext(f)[0] for f in os.listdir(image_folder)])\n",
    "\n",
    "# Get list of annotation files (without extensions)\n",
    "annotation_files = set([os.path.splitext(f)[0]\n",
    "                       for f in os.listdir(annotation_folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Cross-check for missing data\n",
    "label_ids = set(\"p\" + train_labels['Pothole number'].astype(str))\n",
    "\n",
    "# Potholes with complete data\n",
    "complete_data = label_ids.intersection(\n",
    "    image_files).intersection(annotation_files)\n",
    "\n",
    "# Missing components\n",
    "missing_images = label_ids - image_files\n",
    "missing_annotations = label_ids - annotation_files\n",
    "missing_both = missing_images.intersection(missing_annotations)\n",
    "\n",
    "# Filter the original DataFrame to include only complete entries\n",
    "filtered_train_labels = train_labels[(\"p\" + train_labels['Pothole number'].astype(\n",
    "    str)).isin(complete_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_train_labels.to_csv(\n",
    "    './data_full/filtered_train_labels.csv', index=False)\n",
    "\n",
    "# Save the results to CSV files for further analysis\n",
    "missing_images_df = pd.DataFrame(\n",
    "    list(missing_images), columns=['Pothole number'])\n",
    "missing_images_df.to_csv('./data_full/missing_images.csv', index=False)\n",
    "\n",
    "missing_annotations_df = pd.DataFrame(\n",
    "    list(missing_annotations), columns=['Pothole number'])\n",
    "missing_annotations_df.to_csv(\n",
    "    './data_full/missing_annotations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries in train_labels.csv: 644\n",
      "Total images: 485\n",
      "Total annotations: 482\n",
      "\n",
      "Potholes with complete data: 386\n",
      "Potholes missing images: 255\n",
      "Potholes missing annotations: 258\n",
      "Potholes missing both images and annotations: 255\n",
      "\n",
      "Original CSV entries: 644\n",
      "Filtered CSV entries: 386\n",
      "Filtered CSV saved as 'filtered_train_labels.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Output results\n",
    "print(f\"Total entries in train_labels.csv: {len(train_labels)}\")\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Total annotations: {len(annotation_files)}\")\n",
    "print()\n",
    "print(f\"Potholes with complete data: {len(complete_data)}\")\n",
    "print(f\"Potholes missing images: {len(missing_images)}\")\n",
    "print(f\"Potholes missing annotations: {len(missing_annotations)}\")\n",
    "print(f\"Potholes missing both images and annotations: {len(missing_both)}\")\n",
    "print()\n",
    "print(f\"Original CSV entries: {len(train_labels)}\")\n",
    "print(f\"Filtered CSV entries: {len(filtered_train_labels)}\")\n",
    "print(f\"Filtered CSV saved as 'filtered_train_labels.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p1188', 'p1239', 'p1450'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_annotations - missing_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new filtered image/annotation folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the filtered train_labels.csv (from the previous step)\n",
    "filtered_train_labels = pd.read_csv('./data_full/filtered_train_labels.csv')\n",
    "filtered_ids = set(filtered_train_labels['Pothole number'].astype(str))\n",
    "\n",
    "# Define the original and new folder paths\n",
    "# Replace with your actual image folder path\n",
    "original_image_folder = './data_full/train_images'\n",
    "# Replace with your actual annotation folder path\n",
    "original_annotation_folder = './data_full/train_annotations'\n",
    "\n",
    "new_image_folder = './data_full/filtered_train_images'\n",
    "new_annotation_folder = './data_full/filtered_train_annotations'\n",
    "\n",
    "# Create new folders if they don't exist\n",
    "os.makedirs(new_image_folder, exist_ok=True)\n",
    "os.makedirs(new_annotation_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered images copied to ./data_full/filtered_train_images\n",
      "Filtered annotations copied to ./data_full/filtered_train_annotations\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Filter and copy images\n",
    "for pothole_id in filtered_ids:\n",
    "    image_file = f\"p{pothole_id}.jpg\"\n",
    "    annotation_file = f\"p{pothole_id}.txt\"\n",
    "\n",
    "    # Copy image\n",
    "    if os.path.exists(os.path.join(original_image_folder, image_file)):\n",
    "        shutil.copy(os.path.join(original_image_folder,\n",
    "                    image_file), new_image_folder)\n",
    "\n",
    "    # Copy annotation\n",
    "    if os.path.exists(os.path.join(original_annotation_folder, annotation_file)):\n",
    "        shutil.copy(os.path.join(original_annotation_folder,\n",
    "                    annotation_file), new_annotation_folder)\n",
    "\n",
    "print(f\"Filtered images copied to {new_image_folder}\")\n",
    "print(f\"Filtered annotations copied to {new_annotation_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually, I have also constructed a validation set of the data from the tail-end of the original filtered training set data using an 80/20 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** All this data analysis has been done with the original data, not re-annotated or modified yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Really bad data in original form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in its current state is not good to work with. Although it has been cleaned up by matching up the training labels with the correct images and annotations, there is still some improvement to be made. Specifically, the YOLOv8 bounding box detection model struggles with its accuracy especially when identifying the L2 boxes of the meter sticks. This is because there are so few labels of L2, and they are done inconsistently. The model does not understand the difference between L1 and L2, because there is no difference. They are both just halves of a meter stick, and so having the label ambiguity poisons the model. So, we can reduce the labels and remove L2 altogether to have a simplified model which only detects potholes and half-meter sticks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the annotation folder\n",
    "annotation_folder = './data_full/filtered_train_annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace L2 labels with L1 in each annotation file\n",
    "def update_annotations(folder):\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(folder, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            # Replace label '2' with '1'\n",
    "            updated_lines = [line.replace('2 ', '1 ') for line in lines]\n",
    "\n",
    "            # Write the updated content back to the file\n",
    "            with open(file_path, 'w') as file:\n",
    "                file.writelines(updated_lines)\n",
    "\n",
    "            print(f\"Updated {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated p101.txt\n",
      "Updated p102.txt\n",
      "Updated p1032.txt\n",
      "Updated p1033.txt\n",
      "Updated p1034.txt\n",
      "Updated p1035.txt\n",
      "Updated p1036.txt\n",
      "Updated p1037.txt\n",
      "Updated p1038.txt\n",
      "Updated p1039.txt\n",
      "Updated p1041.txt\n",
      "Updated p1042.txt\n",
      "Updated p1043.txt\n",
      "Updated p1047.txt\n",
      "Updated p1048.txt\n",
      "Updated p1049.txt\n",
      "Updated p1051.txt\n",
      "Updated p1052.txt\n",
      "Updated p1054.txt\n",
      "Updated p1055.txt\n",
      "Updated p1056.txt\n",
      "Updated p1058.txt\n",
      "Updated p1059.txt\n",
      "Updated p106.txt\n",
      "Updated p1060.txt\n",
      "Updated p1061.txt\n",
      "Updated p1062.txt\n",
      "Updated p1063.txt\n",
      "Updated p1064.txt\n",
      "Updated p1065.txt\n",
      "Updated p1069.txt\n",
      "Updated p107.txt\n",
      "Updated p1070.txt\n",
      "Updated p1071.txt\n",
      "Updated p1072.txt\n",
      "Updated p1073.txt\n",
      "Updated p1074.txt\n",
      "Updated p1075.txt\n",
      "Updated p1076.txt\n",
      "Updated p1077.txt\n",
      "Updated p1078.txt\n",
      "Updated p1079.txt\n",
      "Updated p1080.txt\n",
      "Updated p1081.txt\n",
      "Updated p1082.txt\n",
      "Updated p1083.txt\n",
      "Updated p1084.txt\n",
      "Updated p1087.txt\n",
      "Updated p1088.txt\n",
      "Updated p1089.txt\n",
      "Updated p109.txt\n",
      "Updated p1090.txt\n",
      "Updated p1091.txt\n",
      "Updated p1092.txt\n",
      "Updated p1095.txt\n",
      "Updated p1096.txt\n",
      "Updated p1097.txt\n",
      "Updated p1098.txt\n",
      "Updated p1099.txt\n",
      "Updated p110.txt\n",
      "Updated p1100.txt\n",
      "Updated p1101.txt\n",
      "Updated p1102.txt\n",
      "Updated p1103.txt\n",
      "Updated p1104.txt\n",
      "Updated p1105.txt\n",
      "Updated p1106.txt\n",
      "Updated p1107.txt\n",
      "Updated p1108.txt\n",
      "Updated p1109.txt\n",
      "Updated p111.txt\n",
      "Updated p1110.txt\n",
      "Updated p1111.txt\n",
      "Updated p1112.txt\n",
      "Updated p1113.txt\n",
      "Updated p1114.txt\n",
      "Updated p1116.txt\n",
      "Updated p1117.txt\n",
      "Updated p1118.txt\n",
      "Updated p1119.txt\n",
      "Updated p112.txt\n",
      "Updated p1120.txt\n",
      "Updated p1121.txt\n",
      "Updated p1122.txt\n",
      "Updated p1123.txt\n",
      "Updated p1125.txt\n",
      "Updated p1126.txt\n",
      "Updated p1127.txt\n",
      "Updated p1128.txt\n",
      "Updated p1129.txt\n",
      "Updated p113.txt\n",
      "Updated p1130.txt\n",
      "Updated p1131.txt\n",
      "Updated p1133.txt\n",
      "Updated p1135.txt\n",
      "Updated p1137.txt\n",
      "Updated p1138.txt\n",
      "Updated p1139.txt\n",
      "Updated p1140.txt\n",
      "Updated p1141.txt\n",
      "Updated p1142.txt\n",
      "Updated p1143.txt\n",
      "Updated p1144.txt\n",
      "Updated p1147.txt\n",
      "Updated p1148.txt\n",
      "Updated p1149.txt\n",
      "Updated p115.txt\n",
      "Updated p1153.txt\n",
      "Updated p1154.txt\n",
      "Updated p1155.txt\n",
      "Updated p1156.txt\n",
      "Updated p1157.txt\n",
      "Updated p1158.txt\n",
      "Updated p1159.txt\n",
      "Updated p116.txt\n",
      "Updated p1160.txt\n",
      "Updated p1164.txt\n",
      "Updated p1165.txt\n",
      "Updated p1166.txt\n",
      "Updated p1167.txt\n",
      "Updated p1168.txt\n",
      "Updated p1169.txt\n",
      "Updated p117.txt\n",
      "Updated p1170.txt\n",
      "Updated p1171.txt\n",
      "Updated p1172.txt\n",
      "Updated p1173.txt\n",
      "Updated p1174.txt\n",
      "Updated p1176.txt\n",
      "Updated p1177.txt\n",
      "Updated p1178.txt\n",
      "Updated p1179.txt\n",
      "Updated p118.txt\n",
      "Updated p1180.txt\n",
      "Updated p1182.txt\n",
      "Updated p1183.txt\n",
      "Updated p1184.txt\n",
      "Updated p1185.txt\n",
      "Updated p1186.txt\n",
      "Updated p1187.txt\n",
      "Updated p1189.txt\n",
      "Updated p119.txt\n",
      "Updated p1190.txt\n",
      "Updated p1192.txt\n",
      "Updated p1193.txt\n",
      "Updated p1194.txt\n",
      "Updated p1195.txt\n",
      "Updated p1196.txt\n",
      "Updated p1197.txt\n",
      "Updated p1199.txt\n",
      "Updated p120.txt\n",
      "Updated p1200.txt\n",
      "Updated p1201.txt\n",
      "Updated p1202.txt\n",
      "Updated p1203.txt\n",
      "Updated p1204.txt\n",
      "Updated p1207.txt\n",
      "Updated p1208.txt\n",
      "Updated p121.txt\n",
      "Updated p1210.txt\n",
      "Updated p1212.txt\n",
      "Updated p1213.txt\n",
      "Updated p1214.txt\n",
      "Updated p1216.txt\n",
      "Updated p1217.txt\n",
      "Updated p1218.txt\n",
      "Updated p1219.txt\n",
      "Updated p122.txt\n",
      "Updated p1221.txt\n",
      "Updated p1224.txt\n",
      "Updated p1225.txt\n",
      "Updated p1226.txt\n",
      "Updated p1227.txt\n",
      "Updated p1228.txt\n",
      "Updated p1229.txt\n",
      "Updated p123.txt\n",
      "Updated p1230.txt\n",
      "Updated p1231.txt\n",
      "Updated p1232.txt\n",
      "Updated p1233.txt\n",
      "Updated p1234.txt\n",
      "Updated p1235.txt\n",
      "Updated p1236.txt\n",
      "Updated p1238.txt\n",
      "Updated p124.txt\n",
      "Updated p1240.txt\n",
      "Updated p1242.txt\n",
      "Updated p1243.txt\n",
      "Updated p1245.txt\n",
      "Updated p1246.txt\n",
      "Updated p1247.txt\n",
      "Updated p1248.txt\n",
      "Updated p125.txt\n",
      "Updated p1251.txt\n",
      "Updated p1253.txt\n",
      "Updated p1254.txt\n",
      "Updated p1256.txt\n",
      "Updated p1257.txt\n",
      "Updated p1258.txt\n",
      "Updated p1259.txt\n",
      "Updated p126.txt\n",
      "Updated p1260.txt\n",
      "Updated p1263.txt\n",
      "Updated p1264.txt\n",
      "Updated p1265.txt\n",
      "Updated p1266.txt\n",
      "Updated p1267.txt\n",
      "Updated p1268.txt\n",
      "Updated p1269.txt\n",
      "Updated p127.txt\n",
      "Updated p1271 (# Name clash 2024-08-09 ybjj27C #).txt\n",
      "Updated p1271.txt\n",
      "Updated p1272.txt\n",
      "Updated p1274.txt\n",
      "Updated p1275.txt\n",
      "Updated p1276.txt\n",
      "Updated p1277.txt\n",
      "Updated p128.txt\n",
      "Updated p1281.txt\n",
      "Updated p1282.txt\n",
      "Updated p1283.txt\n",
      "Updated p1284.txt\n",
      "Updated p1285.txt\n",
      "Updated p1286.txt\n",
      "Updated p1287.txt\n",
      "Updated p1288.txt\n",
      "Updated p129.txt\n",
      "Updated p1291.txt\n",
      "Updated p1292.txt\n",
      "Updated p1293.txt\n",
      "Updated p1294.txt\n",
      "Updated p1295.txt\n",
      "Updated p1297.txt\n",
      "Updated p1298.txt\n",
      "Updated p1299.txt\n",
      "Updated p1302.txt\n",
      "Updated p1303.txt\n",
      "Updated p1304.txt\n",
      "Updated p1305.txt\n",
      "Updated p1306.txt\n",
      "Updated p1308.txt\n",
      "Updated p1309.txt\n",
      "Updated p1310.txt\n",
      "Updated p1312.txt\n",
      "Updated p1313.txt\n",
      "Updated p1314.txt\n",
      "Updated p1315.txt\n",
      "Updated p1316.txt\n",
      "Updated p1318.txt\n",
      "Updated p132.txt\n",
      "Updated p1320.txt\n",
      "Updated p1321.txt\n",
      "Updated p1323.txt\n",
      "Updated p1324.txt\n",
      "Updated p1325.txt\n",
      "Updated p1326.txt\n",
      "Updated p1328.txt\n",
      "Updated p133.txt\n",
      "Updated p1331.txt\n",
      "Updated p1332.txt\n",
      "Updated p1333.txt\n",
      "Updated p1334.txt\n",
      "Updated p1335.txt\n",
      "Updated p1336.txt\n",
      "Updated p1337.txt\n",
      "Updated p134.txt\n",
      "Updated p1341.txt\n",
      "Updated p1342.txt\n",
      "Updated p1343.txt\n",
      "Updated p1344.txt\n",
      "Updated p1345.txt\n",
      "Updated p1346.txt\n",
      "Updated p1347.txt\n",
      "Updated p1349.txt\n",
      "Updated p135.txt\n",
      "Updated p1350.txt\n",
      "Updated p1352.txt\n",
      "Updated p1354.txt\n",
      "Updated p1355.txt\n",
      "Updated p1356.txt\n",
      "Updated p1357.txt\n",
      "Updated p1358.txt\n",
      "Updated p136.txt\n",
      "Updated p138.txt\n",
      "Updated p139.txt\n",
      "Updated p140.txt\n",
      "Updated p1406.txt\n",
      "Updated p1407.txt\n",
      "Updated p1408.txt\n",
      "Updated p141.txt\n",
      "Updated p1410.txt\n",
      "Updated p1412.txt\n",
      "Updated p1413.txt\n",
      "Updated p1414.txt\n",
      "Updated p1416.txt\n",
      "Updated p1417.txt\n",
      "Updated p1418.txt\n",
      "Updated p142.txt\n",
      "Updated p1420.txt\n",
      "Updated p1424.txt\n",
      "Updated p1425 (# Name clash 2024-08-09 sbrknfC #).txt\n",
      "Updated p1425.txt\n",
      "Updated p1427.txt\n",
      "Updated p1428.txt\n",
      "Updated p1429.txt\n",
      "Updated p1431.txt\n",
      "Updated p1433.txt\n",
      "Updated p1439.txt\n",
      "Updated p1440.txt\n",
      "Updated p1442 (# Name clash 2024-08-09 82dv38C #).txt\n",
      "Updated p1442.txt\n",
      "Updated p1443.txt\n",
      "Updated p1445.txt\n",
      "Updated p1449.txt\n",
      "Updated p145.txt\n",
      "Updated p146.txt\n",
      "Updated p147.txt\n",
      "Updated p148.txt\n",
      "Updated p149.txt\n",
      "Updated p150.txt\n",
      "Updated p404.txt\n",
      "Updated p405.txt\n",
      "Updated p407.txt\n",
      "Updated p408.txt\n",
      "Updated p409.txt\n",
      "Updated p410.txt\n",
      "Updated p411.txt\n",
      "Updated p412.txt\n",
      "Updated p413.txt\n",
      "Updated p414.txt\n",
      "Updated p415.txt\n",
      "Updated p416.txt\n",
      "Updated p417.txt\n",
      "Updated p418.txt\n",
      "Updated p419.txt\n",
      "Updated p420.txt\n",
      "Updated p421.txt\n",
      "Updated p422.txt\n",
      "Updated p423.txt\n",
      "Updated p424.txt\n",
      "Updated p425.txt\n",
      "Updated p426.txt\n",
      "Updated p427.txt\n",
      "Updated p428.txt\n",
      "Updated p429.txt\n",
      "Updated p430.txt\n",
      "Updated p431.txt\n",
      "Updated p432.txt\n",
      "Updated p433.txt\n",
      "Updated p435.txt\n",
      "Updated p437.txt\n",
      "Updated p438.txt\n",
      "Updated p439.txt\n",
      "Updated p440.txt\n",
      "Updated p441.txt\n",
      "Updated p442.txt\n",
      "Updated p443.txt\n",
      "Updated p444.txt\n",
      "Updated p445.txt\n",
      "Updated p446.txt\n",
      "Updated p447.txt\n",
      "Updated p448.txt\n",
      "Updated p449.txt\n",
      "Updated p451.txt\n",
      "Updated p452.txt\n",
      "Updated p453.txt\n",
      "Updated p454.txt\n",
      "Updated p455.txt\n",
      "Updated p456.txt\n",
      "Updated p460.txt\n",
      "Updated p461.txt\n",
      "Updated p462.txt\n",
      "Updated p463.txt\n",
      "Updated p465.txt\n",
      "Updated p466.txt\n",
      "Updated p467.txt\n",
      "Updated p468.txt\n",
      "Updated p469.txt\n",
      "Updated p471.txt\n",
      "Updated p472.txt\n",
      "Updated p474.txt\n",
      "Updated p475.txt\n",
      "Updated p476.txt\n",
      "Updated p477.txt\n",
      "Updated p478.txt\n",
      "Updated p497.txt\n",
      "Updated p498.txt\n",
      "Updated p499.txt\n",
      "Updated p500.txt\n",
      "All L2 labels have been updated to L1.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Run the update function\n",
    "update_annotations(annotation_folder)\n",
    "print(\"All L2 labels have been updated to L1.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
